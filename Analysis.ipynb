{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "36535413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "e5ea6764",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('x_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "#x_train = x_train.fillna(0)\n",
    "#y_train = y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "dc01ee7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TARGET'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TARGET'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[745], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(stats\u001b[38;5;241m.\u001b[39mzscore(\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTARGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TARGET'"
     ]
    }
   ],
   "source": [
    "z_scores = np.abs(stats.zscore(x_train['TARGET'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "dbfea9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494,)"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "44cb1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = z_scores > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "90346806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "df660ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.68547886,  6.83601988, -3.82939578, -6.51926827,  6.15113337,\n",
       "        3.95778027, -3.30204961,  3.94894923,  4.33795342, -3.5839355 ,\n",
       "        4.52830948,  4.72441778,  5.01557983,  4.63292846,  3.27542113,\n",
       "        5.57011519,  6.68175385,  3.43757967,  4.56660251, -4.04159037,\n",
       "        3.3049492 ,  3.73916212,  7.13860403,  3.72667811, -3.07592929,\n",
       "        3.73869256,  4.11963512,  7.78657786,  3.9893981 , -4.03063623,\n",
       "        3.69244968,  6.09429709, -3.57919566,  5.01649128,  3.26705797,\n",
       "       -3.51790241,  4.19975462,  6.00990443])"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['TARGET'].values[outliers==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "de4946e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1494.000000</td>\n",
       "      <td>1494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1072.759036</td>\n",
       "      <td>0.089934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>618.013179</td>\n",
       "      <td>1.034582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.519268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>540.250000</td>\n",
       "      <td>-0.219861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1077.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1597.500000</td>\n",
       "      <td>0.269719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2146.000000</td>\n",
       "      <td>7.786578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       TARGET\n",
       "count  1494.000000  1494.000000\n",
       "mean   1072.759036     0.089934\n",
       "std     618.013179     1.034582\n",
       "min       0.000000    -6.519268\n",
       "25%     540.250000    -0.219861\n",
       "50%    1077.500000     0.000000\n",
       "75%    1597.500000     0.269719\n",
       "max    2146.000000     7.786578"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "a3e172d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   2.,   1.,   0.,   3.,   0.,\n",
       "          1.,   0.,   2.,   1.,   3.,   3.,   2.,   3.,   3.,   4.,   8.,\n",
       "          9.,   6.,   7.,  12.,  11.,  18.,  27.,  33.,  50.,  60.,  99.,\n",
       "        208., 304., 189., 114.,  74.,  47.,  24.,  19.,  23.,   7.,  12.,\n",
       "         15.,  15.,   6.,  10.,   2.,   2.,   4.,   5.,   4.,   3.,   5.,\n",
       "          3.,   1.,   3.,   1.,   0.,   4.,   0.,   3.,   2.,   1.,   0.,\n",
       "          3.,   2.,   0.,   2.,   0.,   0.,   0.,   1.,   0.,   0.,   1.,\n",
       "          2.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,   0.,   0.,   0.,\n",
       "          1.]),\n",
       " array([-6.51926827, -6.37620981, -6.23315135, -6.09009289, -5.94703443,\n",
       "        -5.80397597, -5.66091751, -5.51785905, -5.37480058, -5.23174212,\n",
       "        -5.08868366, -4.9456252 , -4.80256674, -4.65950828, -4.51644982,\n",
       "        -4.37339136, -4.23033289, -4.08727443, -3.94421597, -3.80115751,\n",
       "        -3.65809905, -3.51504059, -3.37198213, -3.22892366, -3.0858652 ,\n",
       "        -2.94280674, -2.79974828, -2.65668982, -2.51363136, -2.3705729 ,\n",
       "        -2.22751444, -2.08445597, -1.94139751, -1.79833905, -1.65528059,\n",
       "        -1.51222213, -1.36916367, -1.22610521, -1.08304675, -0.93998828,\n",
       "        -0.79692982, -0.65387136, -0.5108129 , -0.36775444, -0.22469598,\n",
       "        -0.08163752,  0.06142095,  0.20447941,  0.34753787,  0.49059633,\n",
       "         0.63365479,  0.77671325,  0.91977171,  1.06283017,  1.20588864,\n",
       "         1.3489471 ,  1.49200556,  1.63506402,  1.77812248,  1.92118094,\n",
       "         2.0642394 ,  2.20729786,  2.35035633,  2.49341479,  2.63647325,\n",
       "         2.77953171,  2.92259017,  3.06564863,  3.20870709,  3.35176556,\n",
       "         3.49482402,  3.63788248,  3.78094094,  3.9239994 ,  4.06705786,\n",
       "         4.21011632,  4.35317478,  4.49623325,  4.63929171,  4.78235017,\n",
       "         4.92540863,  5.06846709,  5.21152555,  5.35458401,  5.49764248,\n",
       "         5.64070094,  5.7837594 ,  5.92681786,  6.06987632,  6.21293478,\n",
       "         6.35599324,  6.4990517 ,  6.64211017,  6.78516863,  6.92822709,\n",
       "         7.07128555,  7.21434401,  7.35740247,  7.50046093,  7.64351939,\n",
       "         7.78657786]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train['TARGET'].values, bins=100, edgecolor='k', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "c5dfde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop('DE_FR_EXCHANGE' , axis=1)\n",
    "x_train = x_train.drop('FR_NET_EXPORT' , axis=1)\n",
    "x_train = x_train.drop('DE_NET_EXPORT' , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6afa59aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020031624892714997"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x_train['FR_CONSUMPTION'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "c890a120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DAY_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DE_CONSUMPTION</th>\n",
       "      <th>FR_CONSUMPTION</th>\n",
       "      <th>FR_DE_EXCHANGE</th>\n",
       "      <th>DE_NET_IMPORT</th>\n",
       "      <th>FR_NET_IMPORT</th>\n",
       "      <th>DE_GAS</th>\n",
       "      <th>FR_GAS</th>\n",
       "      <th>...</th>\n",
       "      <th>FR_RESIDUAL_LOAD</th>\n",
       "      <th>DE_RAIN</th>\n",
       "      <th>FR_RAIN</th>\n",
       "      <th>DE_WIND</th>\n",
       "      <th>FR_WIND</th>\n",
       "      <th>DE_TEMP</th>\n",
       "      <th>FR_TEMP</th>\n",
       "      <th>GAS_RET</th>\n",
       "      <th>COAL_RET</th>\n",
       "      <th>CARBON_RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054</td>\n",
       "      <td>206</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.210099</td>\n",
       "      <td>-0.427458</td>\n",
       "      <td>0.606523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.692860</td>\n",
       "      <td>0.441238</td>\n",
       "      <td>-0.213766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444661</td>\n",
       "      <td>-0.172680</td>\n",
       "      <td>-0.556356</td>\n",
       "      <td>-0.790823</td>\n",
       "      <td>-0.283160</td>\n",
       "      <td>-1.069070</td>\n",
       "      <td>-0.063404</td>\n",
       "      <td>0.339041</td>\n",
       "      <td>0.124552</td>\n",
       "      <td>-0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2049</td>\n",
       "      <td>501</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.022399</td>\n",
       "      <td>-1.003452</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>0.573520</td>\n",
       "      <td>1.130838</td>\n",
       "      <td>0.174773</td>\n",
       "      <td>0.426940</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.183194</td>\n",
       "      <td>-1.240300</td>\n",
       "      <td>-0.770457</td>\n",
       "      <td>1.522331</td>\n",
       "      <td>0.828412</td>\n",
       "      <td>0.437419</td>\n",
       "      <td>1.831241</td>\n",
       "      <td>-0.659091</td>\n",
       "      <td>0.047114</td>\n",
       "      <td>-0.490365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1924</td>\n",
       "      <td>687</td>\n",
       "      <td>FR</td>\n",
       "      <td>1.395035</td>\n",
       "      <td>1.978665</td>\n",
       "      <td>-1.021305</td>\n",
       "      <td>0.622021</td>\n",
       "      <td>1.682587</td>\n",
       "      <td>2.351913</td>\n",
       "      <td>2.122241</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947273</td>\n",
       "      <td>-0.480700</td>\n",
       "      <td>-0.313338</td>\n",
       "      <td>0.431134</td>\n",
       "      <td>0.487608</td>\n",
       "      <td>0.684884</td>\n",
       "      <td>0.114836</td>\n",
       "      <td>0.535974</td>\n",
       "      <td>0.743338</td>\n",
       "      <td>0.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>720</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.983324</td>\n",
       "      <td>-0.849198</td>\n",
       "      <td>0.839586</td>\n",
       "      <td>0.270870</td>\n",
       "      <td>-0.563230</td>\n",
       "      <td>0.487818</td>\n",
       "      <td>0.194659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.976974</td>\n",
       "      <td>-1.114838</td>\n",
       "      <td>-0.507570</td>\n",
       "      <td>-0.499409</td>\n",
       "      <td>-0.236249</td>\n",
       "      <td>0.350938</td>\n",
       "      <td>-0.417514</td>\n",
       "      <td>0.911652</td>\n",
       "      <td>-0.296168</td>\n",
       "      <td>1.073948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101</td>\n",
       "      <td>818</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.143807</td>\n",
       "      <td>-0.617038</td>\n",
       "      <td>0.924990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.990324</td>\n",
       "      <td>0.238693</td>\n",
       "      <td>-0.240862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526267</td>\n",
       "      <td>-0.541465</td>\n",
       "      <td>-0.424550</td>\n",
       "      <td>-1.088158</td>\n",
       "      <td>-1.011560</td>\n",
       "      <td>0.614338</td>\n",
       "      <td>0.729495</td>\n",
       "      <td>0.245109</td>\n",
       "      <td>1.526606</td>\n",
       "      <td>2.614378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>459</td>\n",
       "      <td>809</td>\n",
       "      <td>DE</td>\n",
       "      <td>1.529204</td>\n",
       "      <td>1.106682</td>\n",
       "      <td>1.855327</td>\n",
       "      <td>0.218658</td>\n",
       "      <td>-1.450426</td>\n",
       "      <td>1.810665</td>\n",
       "      <td>1.388269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876984</td>\n",
       "      <td>0.819520</td>\n",
       "      <td>1.320373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1674</td>\n",
       "      <td>887</td>\n",
       "      <td>FR</td>\n",
       "      <td>1.618582</td>\n",
       "      <td>1.752840</td>\n",
       "      <td>-0.611392</td>\n",
       "      <td>-0.449153</td>\n",
       "      <td>0.152146</td>\n",
       "      <td>1.972779</td>\n",
       "      <td>1.558300</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.932633</td>\n",
       "      <td>-0.085690</td>\n",
       "      <td>0.356356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>748</td>\n",
       "      <td>1083</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.856399</td>\n",
       "      <td>0.489199</td>\n",
       "      <td>0.255778</td>\n",
       "      <td>1.531544</td>\n",
       "      <td>0.829568</td>\n",
       "      <td>2.108764</td>\n",
       "      <td>1.866399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358120</td>\n",
       "      <td>0.207905</td>\n",
       "      <td>0.404763</td>\n",
       "      <td>-0.594595</td>\n",
       "      <td>0.894011</td>\n",
       "      <td>0.256338</td>\n",
       "      <td>0.402316</td>\n",
       "      <td>-1.112899</td>\n",
       "      <td>-0.237835</td>\n",
       "      <td>0.067152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1454</td>\n",
       "      <td>1133</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.560689</td>\n",
       "      <td>-0.343777</td>\n",
       "      <td>0.830239</td>\n",
       "      <td>0.304856</td>\n",
       "      <td>-1.210230</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>0.869742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184862</td>\n",
       "      <td>-0.682815</td>\n",
       "      <td>-0.390304</td>\n",
       "      <td>-0.972088</td>\n",
       "      <td>-1.501930</td>\n",
       "      <td>1.215528</td>\n",
       "      <td>1.338708</td>\n",
       "      <td>0.962812</td>\n",
       "      <td>-5.392852</td>\n",
       "      <td>-0.843812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>359</td>\n",
       "      <td>1118</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.226730</td>\n",
       "      <td>-0.711005</td>\n",
       "      <td>-0.873016</td>\n",
       "      <td>-0.296651</td>\n",
       "      <td>1.547075</td>\n",
       "      <td>0.452981</td>\n",
       "      <td>0.171967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634501</td>\n",
       "      <td>-0.757347</td>\n",
       "      <td>-0.744355</td>\n",
       "      <td>-0.482286</td>\n",
       "      <td>-0.941070</td>\n",
       "      <td>-0.120703</td>\n",
       "      <td>0.391491</td>\n",
       "      <td>1.059829</td>\n",
       "      <td>-0.326640</td>\n",
       "      <td>-0.566724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  DAY_ID COUNTRY  DE_CONSUMPTION  FR_CONSUMPTION  FR_DE_EXCHANGE  \\\n",
       "0     1054     206      FR        0.210099       -0.427458        0.606523   \n",
       "1     2049     501      FR       -0.022399       -1.003452        0.022063   \n",
       "2     1924     687      FR        1.395035        1.978665       -1.021305   \n",
       "3      297     720      DE       -0.983324       -0.849198        0.839586   \n",
       "4     1101     818      FR        0.143807       -0.617038        0.924990   \n",
       "...    ...     ...     ...             ...             ...             ...   \n",
       "1489   459     809      DE        1.529204        1.106682        1.855327   \n",
       "1490  1674     887      FR        1.618582        1.752840       -0.611392   \n",
       "1491   748    1083      DE        0.856399        0.489199        0.255778   \n",
       "1492  1454    1133      FR        0.560689       -0.343777        0.830239   \n",
       "1493   359    1118      DE        0.226730       -0.711005       -0.873016   \n",
       "\n",
       "      DE_NET_IMPORT  FR_NET_IMPORT    DE_GAS    FR_GAS  ...  FR_RESIDUAL_LOAD  \\\n",
       "0               NaN      -0.692860  0.441238 -0.213766  ...         -0.444661   \n",
       "1          0.573520       1.130838  0.174773  0.426940  ...         -1.183194   \n",
       "2          0.622021       1.682587  2.351913  2.122241  ...          1.947273   \n",
       "3          0.270870      -0.563230  0.487818  0.194659  ...         -0.976974   \n",
       "4               NaN      -0.990324  0.238693 -0.240862  ...         -0.526267   \n",
       "...             ...            ...       ...       ...  ...               ...   \n",
       "1489       0.218658      -1.450426  1.810665  1.388269  ...          0.509514   \n",
       "1490      -0.449153       0.152146  1.972779  1.558300  ...          1.666252   \n",
       "1491       1.531544       0.829568  2.108764  1.866399  ...          0.358120   \n",
       "1492       0.304856      -1.210230 -0.003973  0.869742  ...         -0.184862   \n",
       "1493      -0.296651       1.547075  0.452981  0.171967  ...         -0.634501   \n",
       "\n",
       "       DE_RAIN   FR_RAIN   DE_WIND   FR_WIND   DE_TEMP   FR_TEMP   GAS_RET  \\\n",
       "0    -0.172680 -0.556356 -0.790823 -0.283160 -1.069070 -0.063404  0.339041   \n",
       "1    -1.240300 -0.770457  1.522331  0.828412  0.437419  1.831241 -0.659091   \n",
       "2    -0.480700 -0.313338  0.431134  0.487608  0.684884  0.114836  0.535974   \n",
       "3    -1.114838 -0.507570 -0.499409 -0.236249  0.350938 -0.417514  0.911652   \n",
       "4    -0.541465 -0.424550 -1.088158 -1.011560  0.614338  0.729495  0.245109   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1489       NaN       NaN       NaN       NaN       NaN       NaN  0.876984   \n",
       "1490       NaN       NaN       NaN       NaN       NaN       NaN  0.932633   \n",
       "1491  0.207905  0.404763 -0.594595  0.894011  0.256338  0.402316 -1.112899   \n",
       "1492 -0.682815 -0.390304 -0.972088 -1.501930  1.215528  1.338708  0.962812   \n",
       "1493 -0.757347 -0.744355 -0.482286 -0.941070 -0.120703  0.391491  1.059829   \n",
       "\n",
       "      COAL_RET  CARBON_RET  \n",
       "0     0.124552   -0.002445  \n",
       "1     0.047114   -0.490365  \n",
       "2     0.743338    0.204952  \n",
       "3    -0.296168    1.073948  \n",
       "4     1.526606    2.614378  \n",
       "...        ...         ...  \n",
       "1489  0.819520    1.320373  \n",
       "1490 -0.085690    0.356356  \n",
       "1491 -0.237835    0.067152  \n",
       "1492 -5.392852   -0.843812  \n",
       "1493 -0.326640   -0.566724  \n",
       "\n",
       "[1494 rows x 32 columns]"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50d0a8e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_fr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx_train_fr\u001b[49m\u001b[38;5;241m.\u001b[39miloc[: , \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_fr' is not defined"
     ]
    }
   ],
   "source": [
    "x_train_fr.iloc[: , -3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "f038b711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    3,    5,    7,    8,   11,   12,   14,   16,   20,   21,\n",
       "         22,   23,   25,   26,   27,   31,   34,   36,   37,   38,   40,\n",
       "         41,   42,   46,   49,   53,   55,   57,   60,   61,   62,   66,\n",
       "         68,   70,   71,   72,   73,   74,   77,   78,   81,   82,   83,\n",
       "         86,   87,   88,   92,   93,   94,   96,   97,   98,   99,  101,\n",
       "        102,  104,  105,  106,  107,  108,  109,  112,  116,  117,  118,\n",
       "        120,  121,  122,  124,  127,  130,  131,  134,  135,  137,  143,\n",
       "        144,  146,  147,  149,  150,  152,  154,  155,  158,  162,  163,\n",
       "        165,  166,  168,  169,  170,  172,  175,  178,  179,  180,  181,\n",
       "        183,  184,  187,  188,  189,  191,  192,  194,  195,  198,  199,\n",
       "        201,  203,  204,  205,  207,  209,  214,  217,  219,  220,  221,\n",
       "        222,  223,  225,  229,  230,  231,  232,  236,  237,  239,  240,\n",
       "        243,  246,  247,  250,  251,  253,  257,  258,  262,  263,  266,\n",
       "        267,  268,  269,  270,  272,  274,  276,  277,  278,  279,  280,\n",
       "        281,  282,  284,  285,  286,  287,  289,  290,  292,  293,  294,\n",
       "        296,  297,  298,  302,  304,  305,  307,  309,  310,  311,  315,\n",
       "        318,  319,  320,  325,  327,  328,  329,  330,  331,  333,  336,\n",
       "        337,  340,  341,  344,  345,  346,  347,  348,  349,  351,  353,\n",
       "        355,  356,  357,  359,  361,  363,  364,  365,  371,  374,  377,\n",
       "        378,  380,  381,  384,  387,  389,  391,  393,  396,  398,  399,\n",
       "        400,  403,  406,  409,  412,  413,  414,  416,  417,  419,  420,\n",
       "        422,  423,  424,  425,  426,  427,  429,  430,  431,  434,  436,\n",
       "        437,  442,  444,  445,  446,  449,  453,  454,  456,  457,  460,\n",
       "        461,  463,  466,  467,  469,  470,  473,  474,  476,  479,  480,\n",
       "        481,  482,  490,  492,  494,  495,  497,  500,  501,  503,  505,\n",
       "        508,  510,  512,  514,  515,  516,  517,  519,  521,  522,  523,\n",
       "        525,  526,  530,  533,  535,  536,  537,  538,  539,  540,  542,\n",
       "        543,  544,  545,  547,  549,  550,  552,  553,  554,  556,  557,\n",
       "        558,  560,  561,  562,  564,  565,  566,  567,  568,  573,  574,\n",
       "        579,  580,  582,  584,  586,  587,  589,  591,  592,  593,  595,\n",
       "        598,  600,  601,  602,  604,  605,  606,  608,  609,  610,  612,\n",
       "        615,  616,  617,  620,  622,  623,  624,  626,  627,  629,  631,\n",
       "        635,  638,  640,  641,  642,  643,  644,  645,  647,  648,  649,\n",
       "        650,  652,  653,  654,  655,  656,  659,  660,  662,  663,  664,\n",
       "        665,  666,  667,  668,  671,  672,  673,  674,  675,  677,  678,\n",
       "        679,  681,  682,  684,  685,  686,  687,  689,  690,  693,  696,\n",
       "        697,  700,  701,  702,  704,  709,  711,  712,  713,  714,  715,\n",
       "        718,  720,  722,  724,  725,  729,  730,  732,  733,  735,  736,\n",
       "        739,  741,  742,  746,  750,  754,  757,  761,  762,  763,  765,\n",
       "        767,  771,  773,  775,  776,  778,  779,  780,  781,  782,  783,\n",
       "        785,  788,  789,  790,  791,  792,  794,  795,  796,  797,  798,\n",
       "        799,  803,  806,  807,  808,  809,  815,  816,  817,  820,  821,\n",
       "        823,  824,  826,  828,  831,  832,  833,  835,  836,  841,  844,\n",
       "        847,  851,  852,  855,  856,  859,  861,  862,  864,  872,  877,\n",
       "        878,  881,  882,  884,  887,  888,  890,  893,  895,  896,  897,\n",
       "        899,  901,  903,  904,  905,  906,  907,  908,  909,  910,  914,\n",
       "        918,  919,  920,  921,  922,  923,  932,  933,  935,  936,  938,\n",
       "        939,  941,  942,  944,  948,  950,  954,  956,  957,  961,  964,\n",
       "        965,  968,  972,  973,  974,  975,  977,  980,  982,  983,  985,\n",
       "        988,  989,  990,  994,  996,  998, 1000, 1001, 1002, 1003, 1005,\n",
       "       1007, 1008, 1011, 1012, 1016, 1017, 1018, 1019, 1021, 1022, 1024,\n",
       "       1027, 1030, 1032, 1036, 1037, 1040, 1042, 1044, 1045, 1046, 1052,\n",
       "       1054, 1055, 1058, 1059, 1060, 1063, 1065, 1070, 1071, 1075, 1076,\n",
       "       1077, 1079, 1083, 1086, 1088, 1089, 1092, 1095, 1097, 1098, 1100,\n",
       "       1101, 1107, 1110, 1111, 1112, 1116, 1117, 1118, 1119, 1120, 1127,\n",
       "       1129, 1130, 1132, 1133, 1134, 1135, 1137, 1138, 1140, 1144, 1145,\n",
       "       1146, 1147, 1148, 1156, 1165, 1168, 1169, 1175, 1178, 1179, 1181,\n",
       "       1182, 1183, 1184, 1187, 1188, 1190, 1193, 1198, 1199, 1200, 1201,\n",
       "       1202, 1207, 1208, 1212, 1213])"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(x_train_de[\"DAY_ID\"].values[x_train['COUNTRY'].values=='DE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "85296009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a1= [1,2,3]\n",
    "b1=[5,6,7]\n",
    "a2 = [2,1,3]\n",
    "b2 = [6,5,7]\n",
    "print(spearmanr(a1,b1).correlation)\n",
    "print(spearmanr(a2,b2).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b58e93b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3240557281033911\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(0.01*x_train['CARBON_RET'].values[x_train['COUNTRY'].values=='DE'] + x_train['DE_RESIDUAL_LOAD'].values[x_train['COUNTRY'].values=='DE'], y_train['TARGET'].values[x_train['COUNTRY'].values=='DE']).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "18a6bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_de = x_train.copy()\n",
    "columnsde = x_train_de.columns\n",
    "for col in columnsde:\n",
    "    if (not(col=='COUNTRY')):\n",
    "        x_train_de[col].fillna(x_train_de[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "6d4c2860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DAY_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DE_CONSUMPTION</th>\n",
       "      <th>FR_CONSUMPTION</th>\n",
       "      <th>FR_DE_EXCHANGE</th>\n",
       "      <th>DE_NET_IMPORT</th>\n",
       "      <th>FR_NET_IMPORT</th>\n",
       "      <th>DE_GAS</th>\n",
       "      <th>FR_GAS</th>\n",
       "      <th>...</th>\n",
       "      <th>FR_RESIDUAL_LOAD</th>\n",
       "      <th>DE_RAIN</th>\n",
       "      <th>FR_RAIN</th>\n",
       "      <th>DE_WIND</th>\n",
       "      <th>FR_WIND</th>\n",
       "      <th>DE_TEMP</th>\n",
       "      <th>FR_TEMP</th>\n",
       "      <th>GAS_RET</th>\n",
       "      <th>COAL_RET</th>\n",
       "      <th>CARBON_RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054</td>\n",
       "      <td>206</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.210099</td>\n",
       "      <td>-0.427458</td>\n",
       "      <td>0.606523</td>\n",
       "      <td>0.256332</td>\n",
       "      <td>-0.692860</td>\n",
       "      <td>0.441238</td>\n",
       "      <td>-0.213766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444661</td>\n",
       "      <td>-0.172680</td>\n",
       "      <td>-0.556356</td>\n",
       "      <td>-0.790823</td>\n",
       "      <td>-0.283160</td>\n",
       "      <td>-1.069070</td>\n",
       "      <td>-0.063404</td>\n",
       "      <td>0.339041</td>\n",
       "      <td>0.124552</td>\n",
       "      <td>-0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2049</td>\n",
       "      <td>501</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.022399</td>\n",
       "      <td>-1.003452</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>0.573520</td>\n",
       "      <td>1.130838</td>\n",
       "      <td>0.174773</td>\n",
       "      <td>0.426940</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.183194</td>\n",
       "      <td>-1.240300</td>\n",
       "      <td>-0.770457</td>\n",
       "      <td>1.522331</td>\n",
       "      <td>0.828412</td>\n",
       "      <td>0.437419</td>\n",
       "      <td>1.831241</td>\n",
       "      <td>-0.659091</td>\n",
       "      <td>0.047114</td>\n",
       "      <td>-0.490365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1924</td>\n",
       "      <td>687</td>\n",
       "      <td>FR</td>\n",
       "      <td>1.395035</td>\n",
       "      <td>1.978665</td>\n",
       "      <td>-1.021305</td>\n",
       "      <td>0.622021</td>\n",
       "      <td>1.682587</td>\n",
       "      <td>2.351913</td>\n",
       "      <td>2.122241</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947273</td>\n",
       "      <td>-0.480700</td>\n",
       "      <td>-0.313338</td>\n",
       "      <td>0.431134</td>\n",
       "      <td>0.487608</td>\n",
       "      <td>0.684884</td>\n",
       "      <td>0.114836</td>\n",
       "      <td>0.535974</td>\n",
       "      <td>0.743338</td>\n",
       "      <td>0.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>720</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.983324</td>\n",
       "      <td>-0.849198</td>\n",
       "      <td>0.839586</td>\n",
       "      <td>0.270870</td>\n",
       "      <td>-0.563230</td>\n",
       "      <td>0.487818</td>\n",
       "      <td>0.194659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.976974</td>\n",
       "      <td>-1.114838</td>\n",
       "      <td>-0.507570</td>\n",
       "      <td>-0.499409</td>\n",
       "      <td>-0.236249</td>\n",
       "      <td>0.350938</td>\n",
       "      <td>-0.417514</td>\n",
       "      <td>0.911652</td>\n",
       "      <td>-0.296168</td>\n",
       "      <td>1.073948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101</td>\n",
       "      <td>818</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.143807</td>\n",
       "      <td>-0.617038</td>\n",
       "      <td>0.924990</td>\n",
       "      <td>0.256332</td>\n",
       "      <td>-0.990324</td>\n",
       "      <td>0.238693</td>\n",
       "      <td>-0.240862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526267</td>\n",
       "      <td>-0.541465</td>\n",
       "      <td>-0.424550</td>\n",
       "      <td>-1.088158</td>\n",
       "      <td>-1.011560</td>\n",
       "      <td>0.614338</td>\n",
       "      <td>0.729495</td>\n",
       "      <td>0.245109</td>\n",
       "      <td>1.526606</td>\n",
       "      <td>2.614378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>459</td>\n",
       "      <td>809</td>\n",
       "      <td>DE</td>\n",
       "      <td>1.529204</td>\n",
       "      <td>1.106682</td>\n",
       "      <td>1.855327</td>\n",
       "      <td>0.218658</td>\n",
       "      <td>-1.450426</td>\n",
       "      <td>1.810665</td>\n",
       "      <td>1.388269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509514</td>\n",
       "      <td>-0.037831</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.109480</td>\n",
       "      <td>0.123099</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.876984</td>\n",
       "      <td>0.819520</td>\n",
       "      <td>1.320373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1674</td>\n",
       "      <td>887</td>\n",
       "      <td>FR</td>\n",
       "      <td>1.618582</td>\n",
       "      <td>1.752840</td>\n",
       "      <td>-0.611392</td>\n",
       "      <td>-0.449153</td>\n",
       "      <td>0.152146</td>\n",
       "      <td>1.972779</td>\n",
       "      <td>1.558300</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666252</td>\n",
       "      <td>-0.037831</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.109480</td>\n",
       "      <td>0.123099</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.932633</td>\n",
       "      <td>-0.085690</td>\n",
       "      <td>0.356356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>748</td>\n",
       "      <td>1083</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.856399</td>\n",
       "      <td>0.489199</td>\n",
       "      <td>0.255778</td>\n",
       "      <td>1.531544</td>\n",
       "      <td>0.829568</td>\n",
       "      <td>2.108764</td>\n",
       "      <td>1.866399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358120</td>\n",
       "      <td>0.207905</td>\n",
       "      <td>0.404763</td>\n",
       "      <td>-0.594595</td>\n",
       "      <td>0.894011</td>\n",
       "      <td>0.256338</td>\n",
       "      <td>0.402316</td>\n",
       "      <td>-1.112899</td>\n",
       "      <td>-0.237835</td>\n",
       "      <td>0.067152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1454</td>\n",
       "      <td>1133</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.560689</td>\n",
       "      <td>-0.343777</td>\n",
       "      <td>0.830239</td>\n",
       "      <td>0.304856</td>\n",
       "      <td>-1.210230</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>0.869742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184862</td>\n",
       "      <td>-0.682815</td>\n",
       "      <td>-0.390304</td>\n",
       "      <td>-0.972088</td>\n",
       "      <td>-1.501930</td>\n",
       "      <td>1.215528</td>\n",
       "      <td>1.338708</td>\n",
       "      <td>0.962812</td>\n",
       "      <td>-5.392852</td>\n",
       "      <td>-0.843812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>359</td>\n",
       "      <td>1118</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.226730</td>\n",
       "      <td>-0.711005</td>\n",
       "      <td>-0.873016</td>\n",
       "      <td>-0.296651</td>\n",
       "      <td>1.547075</td>\n",
       "      <td>0.452981</td>\n",
       "      <td>0.171967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634501</td>\n",
       "      <td>-0.757347</td>\n",
       "      <td>-0.744355</td>\n",
       "      <td>-0.482286</td>\n",
       "      <td>-0.941070</td>\n",
       "      <td>-0.120703</td>\n",
       "      <td>0.391491</td>\n",
       "      <td>1.059829</td>\n",
       "      <td>-0.326640</td>\n",
       "      <td>-0.566724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  DAY_ID COUNTRY  DE_CONSUMPTION  FR_CONSUMPTION  FR_DE_EXCHANGE  \\\n",
       "0     1054     206      FR        0.210099       -0.427458        0.606523   \n",
       "1     2049     501      FR       -0.022399       -1.003452        0.022063   \n",
       "2     1924     687      FR        1.395035        1.978665       -1.021305   \n",
       "3      297     720      DE       -0.983324       -0.849198        0.839586   \n",
       "4     1101     818      FR        0.143807       -0.617038        0.924990   \n",
       "...    ...     ...     ...             ...             ...             ...   \n",
       "1489   459     809      DE        1.529204        1.106682        1.855327   \n",
       "1490  1674     887      FR        1.618582        1.752840       -0.611392   \n",
       "1491   748    1083      DE        0.856399        0.489199        0.255778   \n",
       "1492  1454    1133      FR        0.560689       -0.343777        0.830239   \n",
       "1493   359    1118      DE        0.226730       -0.711005       -0.873016   \n",
       "\n",
       "      DE_NET_IMPORT  FR_NET_IMPORT    DE_GAS    FR_GAS  ...  FR_RESIDUAL_LOAD  \\\n",
       "0          0.256332      -0.692860  0.441238 -0.213766  ...         -0.444661   \n",
       "1          0.573520       1.130838  0.174773  0.426940  ...         -1.183194   \n",
       "2          0.622021       1.682587  2.351913  2.122241  ...          1.947273   \n",
       "3          0.270870      -0.563230  0.487818  0.194659  ...         -0.976974   \n",
       "4          0.256332      -0.990324  0.238693 -0.240862  ...         -0.526267   \n",
       "...             ...            ...       ...       ...  ...               ...   \n",
       "1489       0.218658      -1.450426  1.810665  1.388269  ...          0.509514   \n",
       "1490      -0.449153       0.152146  1.972779  1.558300  ...          1.666252   \n",
       "1491       1.531544       0.829568  2.108764  1.866399  ...          0.358120   \n",
       "1492       0.304856      -1.210230 -0.003973  0.869742  ...         -0.184862   \n",
       "1493      -0.296651       1.547075  0.452981  0.171967  ...         -0.634501   \n",
       "\n",
       "       DE_RAIN   FR_RAIN   DE_WIND   FR_WIND   DE_TEMP   FR_TEMP   GAS_RET  \\\n",
       "0    -0.172680 -0.556356 -0.790823 -0.283160 -1.069070 -0.063404  0.339041   \n",
       "1    -1.240300 -0.770457  1.522331  0.828412  0.437419  1.831241 -0.659091   \n",
       "2    -0.480700 -0.313338  0.431134  0.487608  0.684884  0.114836  0.535974   \n",
       "3    -1.114838 -0.507570 -0.499409 -0.236249  0.350938 -0.417514  0.911652   \n",
       "4    -0.541465 -0.424550 -1.088158 -1.011560  0.614338  0.729495  0.245109   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1489 -0.037831  0.019357  0.109480  0.123099  0.009451  0.008404  0.876984   \n",
       "1490 -0.037831  0.019357  0.109480  0.123099  0.009451  0.008404  0.932633   \n",
       "1491  0.207905  0.404763 -0.594595  0.894011  0.256338  0.402316 -1.112899   \n",
       "1492 -0.682815 -0.390304 -0.972088 -1.501930  1.215528  1.338708  0.962812   \n",
       "1493 -0.757347 -0.744355 -0.482286 -0.941070 -0.120703  0.391491  1.059829   \n",
       "\n",
       "      COAL_RET  CARBON_RET  \n",
       "0     0.124552   -0.002445  \n",
       "1     0.047114   -0.490365  \n",
       "2     0.743338    0.204952  \n",
       "3    -0.296168    1.073948  \n",
       "4     1.526606    2.614378  \n",
       "...        ...         ...  \n",
       "1489  0.819520    1.320373  \n",
       "1490 -0.085690    0.356356  \n",
       "1491 -0.237835    0.067152  \n",
       "1492 -5.392852   -0.843812  \n",
       "1493 -0.326640   -0.566724  \n",
       "\n",
       "[1494 rows x 32 columns]"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "81ea3895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0166080306957852"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "spearmanr(np.random.permutation(x_train_de['DE_NET_IMPORT'].values[x_train_de['COUNTRY'].values=='DE']), np.random.permutation(y_train['TARGET'].values[x_train_de['COUNTRY'].values=='DE'])).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "98dde4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:-0.00929776719886291\n",
      "DAY_ID:0.008881813743038995\n",
      "COUNTRY:nan\n",
      "DE_CONSUMPTION:-0.07173574456340875\n",
      "FR_CONSUMPTION:-0.03365079256173211\n",
      "FR_DE_EXCHANGE:0.09440220537032709\n",
      "DE_NET_IMPORT:0.30620421549756394\n",
      "FR_NET_IMPORT:0.004076298774337723\n",
      "DE_GAS:0.2534095234587315\n",
      "FR_GAS:0.072783594380426\n",
      "DE_COAL:0.14205372493654747\n",
      "FR_COAL:0.03262107496293653\n",
      "DE_HYDRO:0.21790028292061114\n",
      "FR_HYDRO:0.058362038936583795\n",
      "DE_NUCLEAR:0.012366411484973836\n",
      "FR_NUCLEAR:-0.00888456720595872\n",
      "DE_SOLAR:0.021201529065667447\n",
      "FR_SOLAR:0.04648287820565579\n",
      "DE_WINDPOW:-0.30093322983322035\n",
      "FR_WINDPOW:-0.1998195714429064\n",
      "DE_LIGNITE:0.12460534779154166\n",
      "DE_RESIDUAL_LOAD:0.32433450859934143\n",
      "FR_RESIDUAL_LOAD:0.03995193446794366\n",
      "DE_RAIN:nan\n",
      "FR_RAIN:nan\n",
      "DE_WIND:nan\n",
      "FR_WIND:nan\n",
      "DE_TEMP:nan\n",
      "FR_TEMP:nan\n",
      "GAS_RET:-0.015835051278364626\n",
      "COAL_RET:-0.020653454761500864\n",
      "CARBON_RET:0.01036583997929758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pouya/Library/Python/3.9/lib/python/site-packages/scipy/stats/_stats_py.py:4921: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    }
   ],
   "source": [
    "x_train_de = x_train.copy()\n",
    "columnsde = x_train_de.columns\n",
    "for i in range(len(columnsde)):\n",
    "    corr = spearmanr(x_train_de[columnsde[i]].values[x_train_de['COUNTRY'].values=='DE'], y_train['TARGET'].values[x_train_de['COUNTRY'].values=='DE']).correlation\n",
    "    print( str(columnsde[i]) + ':' + str(corr))\n",
    "    if (abs(corr)<0.05) & (i>=3):\n",
    "        x_train_de = x_train_de.drop(columns = [columnsde[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "f9fd4162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:-0.00929776719886291\n",
      "DAY_ID:0.008881813743038995\n",
      "COUNTRY:nan\n",
      "DE_CONSUMPTION:-0.07173574456340875\n",
      "FR_DE_EXCHANGE:0.09440220537032709\n",
      "DE_NET_IMPORT:0.30620421549756394\n",
      "FR_NET_IMPORT:0.004076298774337723\n",
      "FR_COAL:0.03262107496293653\n",
      "DE_HYDRO:0.21790028292061114\n",
      "FR_HYDRO:0.058362038936583795\n",
      "DE_WINDPOW:-0.30093322983322035\n",
      "FR_WINDPOW:-0.1998195714429064\n",
      "DE_RESIDUAL_LOAD:0.32433450859934143\n",
      "DE_RAIN:nan\n",
      "FR_RAIN:nan\n",
      "DE_WIND:nan\n",
      "FR_WIND:nan\n",
      "DE_TEMP:nan\n",
      "FR_TEMP:nan\n",
      "GAS_RET:-0.015835051278364626\n",
      "COAL_RET:-0.020653454761500864\n",
      "CARBON_RET:0.01036583997929758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pouya/Library/Python/3.9/lib/python/site-packages/scipy/stats/_stats_py.py:4921: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    }
   ],
   "source": [
    "columnsfr = x_train_de.columns\n",
    "for i in columnsfr:\n",
    "    print( str(i) + ':' + str(spearmanr(x_train_de[i].values[x_train_de['COUNTRY'].values=='DE'], y_train['TARGET'].values[x_train_de['COUNTRY'].values=='DE']).correlation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1,1,1,1,-1,-1,1,1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cb8aa78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 18)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_de = x_train_de[x_train_de['COUNTRY'] == 'DE']\n",
    "x_train_de.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "199cfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xde = x_train_de.values[:,3:]\n",
    "yde = y_train['TARGET'].values[x_train['COUNTRY'].values=='DE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "88595e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 15)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a59e9ae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 1494 but corresponding boolean dimension is 643",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTARGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train_de\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCOUNTRY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, xde[:,\u001b[38;5;241m0\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 1494 but corresponding boolean dimension is 643"
     ]
    }
   ],
   "source": [
    "plt.plot(y_train['TARGET'].values[x_train['COUNTRY'].values=='DE'], xde[:,0],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "4c84d770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/s7_pzg4x2xxcg7cty448hrxc0000gn/T/ipykernel_53078/1125713096.py:19: OptimizeWarning: Unknown solver options: ftol\n",
      "  result = minimize(fun=lambda x: -spear(x), x0=initial_guess, options={'xtol': xtol, 'ftol': ftol}, method='Newton-CG')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Jacobian is required for Newton-CG method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[630], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m ftol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m  \u001b[38;5;66;03m# Tolerance for the function value\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Use Powell's method for maximization\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mspear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_guess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mftol\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNewton-CG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#result = minimize(fun=lambda x: -spear(x), x0=initial_guess, method='Powell')\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Extract the maximized values and objective function value\u001b[39;00m\n\u001b[1;32m     23\u001b[0m maximized_values \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_minimize.py:693\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    691\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_bfgs(fun, x0, args, jac, callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 693\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_newtoncg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    696\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    697\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_optimize.py:1930\u001b[0m, in \u001b[0;36m_minimize_newtoncg\u001b[0;34m(fun, x0, args, jac, hess, hessp, callback, xtol, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1928\u001b[0m _check_unknown_options(unknown_options)\n\u001b[1;32m   1929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1930\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJacobian is required for Newton-CG method\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1931\u001b[0m fhess_p \u001b[38;5;241m=\u001b[39m hessp\n\u001b[1;32m   1932\u001b[0m fhess \u001b[38;5;241m=\u001b[39m hess\n",
      "\u001b[0;31mValueError\u001b[0m: Jacobian is required for Newton-CG method"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the objective function to maximize\n",
    "def spear(xs):\n",
    "    # Example quadratic function to maximize: -((x-2)^2 + (y-3)^2)\n",
    "    return -pearsonr(np.matmul(xde,xs), yde).correlation\n",
    "\n",
    "\n",
    "# Initial guess or starting point\n",
    "initial_guess = np.zeros((xde.shape[1]))\n",
    "initial_guess = initial_guess + 1\n",
    "#initial_guess = np.array([1,1,1,1,-1,-1,1,1,-1])\n",
    "#bounds = [(-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)]\n",
    "xtol = 1e-6  # Tolerance for parameter values\n",
    "ftol = 1e-6  # Tolerance for the function value\n",
    "\n",
    "# Use Powell's method for maximization\n",
    "result = minimize(fun=lambda x: -spear(x), x0=initial_guess, options={'xtol': xtol, 'ftol': ftol}, method='Newton-CG')\n",
    "#result = minimize(fun=lambda x: -spear(x), x0=initial_guess, method='Powell')\n",
    "\n",
    "# Extract the maximized values and objective function value\n",
    "maximized_values = result.x\n",
    "maximized_objective_value = -result.fun  # Negate the result to get the actual objective value\n",
    "\n",
    "print(\"Maximized Values:\", maximized_values)\n",
    "print(\"Maximized Objective Value:\", maximized_objective_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae5f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe72e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bfe4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa43d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.linspace(-1,1,num=21)\n",
    "bestcoefs = np.zeros((len(coefs), len(coefs), len(coefs), len(coefs), len(coefs), len(coefs), len(coefs), len(coefs), len(coefs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c889589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/21 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for i1 in tqdm(range(len(coefs))):\n",
    "    for i2 in range(len(coefs)):\n",
    "        for i3 in range(len(coefs)):\n",
    "            for i4 in range(len(coefs)):\n",
    "                for i5 in range(len(coefs)):\n",
    "                    for i6 in range(len(coefs)):\n",
    "                        for i7 in range(len(coefs)):\n",
    "                            for i8 in range(len(coefs)):\n",
    "                                for i9 in range(len(coefs)):\n",
    "                                    ri1 = coefs[i1]\n",
    "                                    ri2 = coefs[i2]\n",
    "                                    ri3 = coefs[i3]\n",
    "                                    ri4 = coefs[i4]\n",
    "                                    ri5 = coefs[i5]\n",
    "                                    ri6 = coefs[i6]\n",
    "                                    ri7 = coefs[i7]\n",
    "                                    ri8 = coefs[i8]\n",
    "                                    ri9 = coefs[i9]\n",
    "                                    corr = spearmanr(i1*xde[:,0]+i2*xde[:,1]+i3*xde[:,2]+i4*xde[:,3]+i5*xde[:,4]+i6*xde[:,5]+i7*xde[:,6]+i8*xde[:,7]+i9*xde[:,8], y_train['TARGET'].values[x_train['COUNTRY'].values=='DE']).correlation\n",
    "                                    bestcoefs[i1,i2,i3,i4,i5,i6,i7,i8,i9]= corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-1,1,num=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsfr = x_train.columns\n",
    "for i in columnsfr:\n",
    "    print( str(i) + ':' + str(spearmanr(x_train[i].values[x_train['COUNTRY'].values=='FR'], y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']).correlation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34154afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsfr = x_train.columns\n",
    "for i in columnsfr:\n",
    "    plt.figure()\n",
    "    plt.title(i)\n",
    "    plt.plot(x_train[i].values[x_train['COUNTRY'].values=='FR'], y_train['TARGET'].values[x_train['COUNTRY'].values=='FR'], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed17a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsfr = x_train_fr.columns\n",
    "for i in range(len(columnsfr)):\n",
    "    corr = spearmanr(x_train[columnsfr[i]].values[x_train['COUNTRY'].values=='FR'], y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']).correlation\n",
    "    if (abs(corr)<0.04) & (i>=3):\n",
    "        x_train_fr = x_train_fr.drop(columns = [columnsfr[i]])\n",
    "        print('del')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f53f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train['FR_RESIDUAL_LOAD'].values/x_train['FR_CONSUMPTION'].values)\n",
    "print(spearmanr(x_train['GAS_RET'].values[x_train['COUNTRY'].values=='FR']/np.max(np.abs(x_train['GAS_RET'].values[x_train['COUNTRY'].values=='FR'])), y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']).correlation)\n",
    "print(spearmanr(x_train['COAL_RET'].values[x_train['COUNTRY'].values=='FR'], y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']).correlation)\n",
    "print(spearmanr(x_train['CARBON_RET'].values[x_train['COUNTRY'].values=='FR'], y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']).correlation)\n",
    "print(spearmanr(x_train['GAS_RET'].values[x_train['COUNTRY'].values=='FR'], y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']).correlation)\n",
    "print(spearmanr(x_train['FR_NET_IMPORT'].values[x_train['COUNTRY'].values=='FR'], y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']).correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3097e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newxdata = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d21db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9da35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d326f59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DAY_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>FR_CONSUMPTION</th>\n",
       "      <th>FR_NET_IMPORT</th>\n",
       "      <th>FR_GAS</th>\n",
       "      <th>FR_COAL</th>\n",
       "      <th>FR_HYDRO</th>\n",
       "      <th>FR_NUCLEAR</th>\n",
       "      <th>FR_SOLAR</th>\n",
       "      <th>FR_WINDPOW</th>\n",
       "      <th>FR_RESIDUAL_LOAD</th>\n",
       "      <th>FR_RAIN</th>\n",
       "      <th>FR_WIND</th>\n",
       "      <th>FR_TEMP</th>\n",
       "      <th>GAS_RET</th>\n",
       "      <th>COAL_RET</th>\n",
       "      <th>CARBON_RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054</td>\n",
       "      <td>206</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.427458</td>\n",
       "      <td>-0.692860</td>\n",
       "      <td>-0.213766</td>\n",
       "      <td>0.288782</td>\n",
       "      <td>0.207838</td>\n",
       "      <td>-0.190463</td>\n",
       "      <td>1.248911</td>\n",
       "      <td>-0.269460</td>\n",
       "      <td>-0.444661</td>\n",
       "      <td>-0.556356</td>\n",
       "      <td>-0.283160</td>\n",
       "      <td>-0.063404</td>\n",
       "      <td>0.339041</td>\n",
       "      <td>0.124552</td>\n",
       "      <td>-0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2049</td>\n",
       "      <td>501</td>\n",
       "      <td>FR</td>\n",
       "      <td>-1.003452</td>\n",
       "      <td>1.130838</td>\n",
       "      <td>0.426940</td>\n",
       "      <td>-0.762153</td>\n",
       "      <td>-0.807112</td>\n",
       "      <td>-2.185961</td>\n",
       "      <td>3.237380</td>\n",
       "      <td>-0.107350</td>\n",
       "      <td>-1.183194</td>\n",
       "      <td>-0.770457</td>\n",
       "      <td>0.828412</td>\n",
       "      <td>1.831241</td>\n",
       "      <td>-0.659091</td>\n",
       "      <td>0.047114</td>\n",
       "      <td>-0.490365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1924</td>\n",
       "      <td>687</td>\n",
       "      <td>FR</td>\n",
       "      <td>1.978665</td>\n",
       "      <td>1.682587</td>\n",
       "      <td>2.122241</td>\n",
       "      <td>0.777053</td>\n",
       "      <td>0.779142</td>\n",
       "      <td>0.735137</td>\n",
       "      <td>-0.371039</td>\n",
       "      <td>-0.141239</td>\n",
       "      <td>1.947273</td>\n",
       "      <td>-0.313338</td>\n",
       "      <td>0.487608</td>\n",
       "      <td>0.114836</td>\n",
       "      <td>0.535974</td>\n",
       "      <td>0.743338</td>\n",
       "      <td>0.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101</td>\n",
       "      <td>818</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.617038</td>\n",
       "      <td>-0.990324</td>\n",
       "      <td>-0.240862</td>\n",
       "      <td>-0.274975</td>\n",
       "      <td>-0.795983</td>\n",
       "      <td>0.176935</td>\n",
       "      <td>0.723587</td>\n",
       "      <td>-0.564498</td>\n",
       "      <td>-0.526267</td>\n",
       "      <td>-0.424550</td>\n",
       "      <td>-1.011560</td>\n",
       "      <td>0.729495</td>\n",
       "      <td>0.245109</td>\n",
       "      <td>1.526606</td>\n",
       "      <td>2.614378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1520</td>\n",
       "      <td>467</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.765120</td>\n",
       "      <td>0.200305</td>\n",
       "      <td>0.306422</td>\n",
       "      <td>-0.775944</td>\n",
       "      <td>0.593251</td>\n",
       "      <td>-1.920695</td>\n",
       "      <td>2.054491</td>\n",
       "      <td>-0.245628</td>\n",
       "      <td>-0.860628</td>\n",
       "      <td>-0.193837</td>\n",
       "      <td>-0.917234</td>\n",
       "      <td>0.472708</td>\n",
       "      <td>0.891049</td>\n",
       "      <td>0.861408</td>\n",
       "      <td>1.124457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1776</td>\n",
       "      <td>510</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.704613</td>\n",
       "      <td>-1.112333</td>\n",
       "      <td>-0.456156</td>\n",
       "      <td>-0.793961</td>\n",
       "      <td>0.538795</td>\n",
       "      <td>-0.539194</td>\n",
       "      <td>1.013134</td>\n",
       "      <td>0.149270</td>\n",
       "      <td>-0.795046</td>\n",
       "      <td>1.021354</td>\n",
       "      <td>0.805043</td>\n",
       "      <td>-0.555211</td>\n",
       "      <td>1.946355</td>\n",
       "      <td>0.867074</td>\n",
       "      <td>1.322433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1401</td>\n",
       "      <td>985</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.944372</td>\n",
       "      <td>-0.499653</td>\n",
       "      <td>1.320758</td>\n",
       "      <td>-0.779539</td>\n",
       "      <td>0.375729</td>\n",
       "      <td>0.791698</td>\n",
       "      <td>-1.054641</td>\n",
       "      <td>1.646472</td>\n",
       "      <td>0.634867</td>\n",
       "      <td>-0.441164</td>\n",
       "      <td>-0.658130</td>\n",
       "      <td>0.829517</td>\n",
       "      <td>0.494188</td>\n",
       "      <td>1.011794</td>\n",
       "      <td>1.472650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1728</td>\n",
       "      <td>905</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.459382</td>\n",
       "      <td>1.048997</td>\n",
       "      <td>0.715357</td>\n",
       "      <td>-0.305680</td>\n",
       "      <td>-0.188248</td>\n",
       "      <td>-0.457660</td>\n",
       "      <td>1.953376</td>\n",
       "      <td>0.536297</td>\n",
       "      <td>0.251190</td>\n",
       "      <td>-0.152293</td>\n",
       "      <td>1.697829</td>\n",
       "      <td>-2.069991</td>\n",
       "      <td>1.145686</td>\n",
       "      <td>0.335645</td>\n",
       "      <td>0.606318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1674</td>\n",
       "      <td>887</td>\n",
       "      <td>FR</td>\n",
       "      <td>1.752840</td>\n",
       "      <td>0.152146</td>\n",
       "      <td>1.558300</td>\n",
       "      <td>0.230746</td>\n",
       "      <td>2.957114</td>\n",
       "      <td>0.926279</td>\n",
       "      <td>-0.923261</td>\n",
       "      <td>0.789618</td>\n",
       "      <td>1.666252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.932633</td>\n",
       "      <td>-0.085690</td>\n",
       "      <td>0.356356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1454</td>\n",
       "      <td>1133</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.343777</td>\n",
       "      <td>-1.210230</td>\n",
       "      <td>0.869742</td>\n",
       "      <td>-0.772801</td>\n",
       "      <td>1.447245</td>\n",
       "      <td>-0.196405</td>\n",
       "      <td>0.918251</td>\n",
       "      <td>-0.973969</td>\n",
       "      <td>-0.184862</td>\n",
       "      <td>-0.390304</td>\n",
       "      <td>-1.501930</td>\n",
       "      <td>1.338708</td>\n",
       "      <td>0.962812</td>\n",
       "      <td>-5.392852</td>\n",
       "      <td>-0.843812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>851 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  DAY_ID COUNTRY  FR_CONSUMPTION  FR_NET_IMPORT    FR_GAS   FR_COAL  \\\n",
       "0     1054     206      FR       -0.427458      -0.692860 -0.213766  0.288782   \n",
       "1     2049     501      FR       -1.003452       1.130838  0.426940 -0.762153   \n",
       "2     1924     687      FR        1.978665       1.682587  2.122241  0.777053   \n",
       "4     1101     818      FR       -0.617038      -0.990324 -0.240862 -0.274975   \n",
       "5     1520     467      FR       -0.765120       0.200305  0.306422 -0.775944   \n",
       "...    ...     ...     ...             ...            ...       ...       ...   \n",
       "1483  1776     510      FR       -0.704613      -1.112333 -0.456156 -0.793961   \n",
       "1486  1401     985      FR        0.944372      -0.499653  1.320758 -0.779539   \n",
       "1487  1728     905      FR        0.459382       1.048997  0.715357 -0.305680   \n",
       "1490  1674     887      FR        1.752840       0.152146  1.558300  0.230746   \n",
       "1492  1454    1133      FR       -0.343777      -1.210230  0.869742 -0.772801   \n",
       "\n",
       "      FR_HYDRO  FR_NUCLEAR  FR_SOLAR  FR_WINDPOW  FR_RESIDUAL_LOAD   FR_RAIN  \\\n",
       "0     0.207838   -0.190463  1.248911   -0.269460         -0.444661 -0.556356   \n",
       "1    -0.807112   -2.185961  3.237380   -0.107350         -1.183194 -0.770457   \n",
       "2     0.779142    0.735137 -0.371039   -0.141239          1.947273 -0.313338   \n",
       "4    -0.795983    0.176935  0.723587   -0.564498         -0.526267 -0.424550   \n",
       "5     0.593251   -1.920695  2.054491   -0.245628         -0.860628 -0.193837   \n",
       "...        ...         ...       ...         ...               ...       ...   \n",
       "1483  0.538795   -0.539194  1.013134    0.149270         -0.795046  1.021354   \n",
       "1486  0.375729    0.791698 -1.054641    1.646472          0.634867 -0.441164   \n",
       "1487 -0.188248   -0.457660  1.953376    0.536297          0.251190 -0.152293   \n",
       "1490  2.957114    0.926279 -0.923261    0.789618          1.666252       NaN   \n",
       "1492  1.447245   -0.196405  0.918251   -0.973969         -0.184862 -0.390304   \n",
       "\n",
       "       FR_WIND   FR_TEMP   GAS_RET  COAL_RET  CARBON_RET  \n",
       "0    -0.283160 -0.063404  0.339041  0.124552   -0.002445  \n",
       "1     0.828412  1.831241 -0.659091  0.047114   -0.490365  \n",
       "2     0.487608  0.114836  0.535974  0.743338    0.204952  \n",
       "4    -1.011560  0.729495  0.245109  1.526606    2.614378  \n",
       "5    -0.917234  0.472708  0.891049  0.861408    1.124457  \n",
       "...        ...       ...       ...       ...         ...  \n",
       "1483  0.805043 -0.555211  1.946355  0.867074    1.322433  \n",
       "1486 -0.658130  0.829517  0.494188  1.011794    1.472650  \n",
       "1487  1.697829 -2.069991  1.145686  0.335645    0.606318  \n",
       "1490       NaN       NaN  0.932633 -0.085690    0.356356  \n",
       "1492 -1.501930  1.338708  0.962812 -5.392852   -0.843812  \n",
       "\n",
       "[851 rows x 18 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_fr = x_train[x_train['COUNTRY'] == 'FR']\n",
    "x_train_fr = x_train_fr.drop(columns = [col for col in x_train_fr.columns if 'DE' in col])\n",
    "x_train_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d01a4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdatafr = x_train_fr.iloc[: , 3:].values\n",
    "ydatafr = y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "ffcf40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fr = x_train[x_train['COUNTRY'] == 'FR']\n",
    "#x_train_fr = x_train_fr.drop(columns = [col for col in x_train_fr.columns if 'DE' in col])\n",
    "xdatafr = x_train_fr.iloc[: , -3:].values\n",
    "ydatafr = y_train['TARGET'].values[x_train['COUNTRY'].values=='FR']\n",
    "\n",
    "x_train_de = x_train.copy()\n",
    "columnsde = x_train_de.columns\n",
    "for col in columnsde:\n",
    "    if (not(col=='COUNTRY')):\n",
    "        x_train_de[col].fillna(x_train_de[col].mean(), inplace=True)\n",
    "x_train_de = x_train_de[x_train_de['COUNTRY'] == 'DE']\n",
    "xdatade = x_train_de.iloc[: , 3:].values\n",
    "ydatade = y_train['TARGET'].values[x_train['COUNTRY'].values=='DE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "fe7ce5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_de = x_train_de[x_train_de['COUNTRY'] == 'DE']\n",
    "xdatade = x_train_de.iloc[: , 3:].values\n",
    "ydatade = y_train['TARGET'].values[x_train['COUNTRY'].values=='DE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "ec01cf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 19)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdatade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "25749468",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcompde = np.zeros((xdatade.shape[0],xdatade.shape[1]+1,xdatade.shape[1]))\n",
    "xcompde[:,xdatade.shape[1],:]=xdatade.copy()\n",
    "for i in range (xdatade.shape[1]):\n",
    "    for j in range (xdatade.shape[1]):\n",
    "        xcompde [:,i,j] = xdatade[:,i]*xdatade[:,j]\n",
    "xcompde = np.reshape(xcompde,(xdatade.shape[0],(xdatade.shape[1]+1)*xdatade.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "78019a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcompde = xdatade.copy()\n",
    "dels = []\n",
    "for i in range(xcompde.shape[1]):\n",
    "    corr = spearmanr(xcompde[:,i], ydatade).correlation\n",
    "    if (abs(corr)<0.01):\n",
    "        dels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "eb3b63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcompdefinal = np.delete(xcompde,dels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "2764b5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 26)"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcompdefinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "dc9b3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcompfr = xdatafr.copy()\n",
    "dels = []\n",
    "for i in range(xcompfr.shape[1]):\n",
    "    corr = spearmanr(xcompfr[:,i], ydatafr).correlation\n",
    "    if (abs(corr)<0.1):\n",
    "        dels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "6844e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcompfrfinal = np.delete(xcompfr,dels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "0c06e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcompde = np.zeros((xdatade.shape[0],2*xdatade.shape[1]))\n",
    "xcompde[:,xdatade.shape[1]:]=xdatade.copy()\n",
    "xcompde[:,:xdatade.shape[1]]=1/(xdatade.copy()+0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a53ac8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.01799418,  -1.17896995,   1.18964637, ...,   0.9116521 ,\n",
       "         -0.29616844,   1.07394768],\n",
       "       [-18.28436053,  -1.23405415,  -4.23540126, ...,  -0.35986623,\n",
       "         -0.20395231,  -0.37623403],\n",
       "       [  1.87576567,  -3.02937152,  -2.95035603, ...,   1.17076001,\n",
       "          0.13364288,   0.03387434],\n",
       "       ...,\n",
       "       [  0.65350763,   0.90278598,   0.53869822, ...,   0.8769841 ,\n",
       "          0.81951951,   1.32037276],\n",
       "       [  1.1663175 ,   2.03998898,   3.89441784, ...,  -1.11289854,\n",
       "         -0.23783497,   0.06715239],\n",
       "       [  4.39116305,  -1.40844019,  -1.1467673 , ...,   1.05982889,\n",
       "         -0.32663975,  -0.56672406]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcompdefinal = xcompde.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8565addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximized Values: [ 5.95925454e+03  5.88906424e+00 -8.83738582e+06 -1.32481757e+01\n",
      "  3.08949788e+01  3.08949788e+01 -1.32481757e+01 -1.32481757e+01\n",
      "  3.08949788e+01  3.08949788e+01  3.08949788e+01  3.08949788e+01\n",
      "  3.08949788e+01  3.08949788e+01  3.08949788e+01]\n",
      "Maximized Objective Value: 0.30619888912667\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the objective function to maximize\n",
    "def spear(xs):\n",
    "    # Example quadratic function to maximize: -((x-2)^2 + (y-3)^2)\n",
    "    return -spearmanr(np.matmul(xcompdefinal,xs), ydatade).correlation\n",
    "\n",
    "\n",
    "# Initial guess or starting point\n",
    "initial_guess = np.zeros((xcompdefinal.shape[1]))\n",
    "initial_guess = initial_guess + 1\n",
    "xtol = 1e-5  # Tolerance for parameter values\n",
    "ftol = 1e-5  # Tolerance for the function value\n",
    "\n",
    "# Use Powell's method for maximization\n",
    "result = minimize(fun=lambda x: -spear(x), x0=initial_guess, options={'xtol': xtol, 'ftol': ftol}, method='Powell')\n",
    "#result = minimize(fun=lambda x: -spear(x), x0=initial_guess, method='Powell')\n",
    "\n",
    "# Extract the maximized values and objective function value\n",
    "maximized_values = result.x\n",
    "maximized_objective_value = -result.fun  # Negate the result to get the actual objective value\n",
    "\n",
    "print(\"Maximized Values:\", maximized_values)\n",
    "print(\"Maximized Objective Value:\", maximized_objective_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "95a03919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "f9f20847",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(xcompdefinal, ydatade, test_size=0.5, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "e701de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score (standardize) each column\n",
    "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "af2d7a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X_train==np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "4445dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1829378642964703\n"
     ]
    }
   ],
   "source": [
    "# Create the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=1000, random_state=42 , max_depth = 100)\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "print(spearmanr(Y_pred, Y_test).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19095b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "14bf9143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.1410113666824622\n",
      "0.35850214248962275\n"
     ]
    }
   ],
   "source": [
    "# Create an SVR model\n",
    "svr = SVR(kernel='rbf', C=0.01, epsilon=0.001)\n",
    "\n",
    "# Train the model on the training data\n",
    "svr.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred = svr.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "print(spearmanr(Y_pred, Y_test).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "7e49ac29",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[499], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Perform grid search with cross-validation\u001b[39;00m\n\u001b[1;32m     17\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(svr, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[1;32m     21\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 252\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    317\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    321\u001b[0m (\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 331\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "File \u001b[0;32msklearn/svm/_libsvm.pyx:236\u001b[0m, in \u001b[0;36msklearn.svm._libsvm.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'degree': [2, 3, 4],\n",
    "    'epsilon': [0.01, 0.1, 1],\n",
    "    'coef0': [0, 1, 2]\n",
    "}\n",
    "\n",
    "# Create the SVR model\n",
    "svr = SVR(kernel='poly')\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "# Train the SVR model with the best hyperparameters\n",
    "best_svr = SVR(kernel='poly', **best_params)\n",
    "best_svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "83d78098",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ridge_model \u001b[38;5;241m=\u001b[39m \u001b[43mRidge\u001b[49m(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m ridge_model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ridge' is not defined"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=1.0)\n",
    "print('done')\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "Y_pred = ridge_model.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "5be3ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7847480487011661\n",
      "0.17240238691976745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted values\n",
    "msle = mean_squared_log_error(np.abs(Y_test), np.abs(Y_pred))\n",
    "print(mse)\n",
    "print(spearmanr(Y_pred, Y_test).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "666fc647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2662402470425815\n",
      "0.33327762121476495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=1)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted values\n",
    "msle = mean_squared_log_error(np.abs(Y_test), np.abs(Y_pred))\n",
    "print(mse)\n",
    "print(spearmanr(Y_pred, Y_test).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "22996b43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_model\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mPoissonRegressor()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_glm/glm.py:226\u001b[0m, in \u001b[0;36m_GeneralizedLinearRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    220\u001b[0m linear_loss \u001b[38;5;241m=\u001b[39m LinearModelLoss(\n\u001b[1;32m    221\u001b[0m     base_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_loss,\n\u001b[1;32m    222\u001b[0m     fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[1;32m    223\u001b[0m )\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m linear_loss\u001b[38;5;241m.\u001b[39mbase_loss\u001b[38;5;241m.\u001b[39min_y_true_range(y):\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome value(s) of y are out of the valid range of the loss\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_loss\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# TODO: if alpha=0 check that X is not rank deficient\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# IMPORTANT NOTE: Rescaling of sample_weight:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m#     obj = sum(sample_weight * loss) + 1/2 * alpha * L2.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Note that LinearModelLoss.loss() computes sum(sample_weight * loss).\u001b[39;00m\n\u001b[1;32m    243\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m/\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mValueError\u001b[0m: Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'."
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.PoissonRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted values\n",
    "msle = mean_squared_log_error(np.abs(Y_test), np.abs(Y_pred))\n",
    "print(mse)\n",
    "print(spearmanr(Y_pred, Y_test).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387fcaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred[:10])\n",
    "print(Y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fa731ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2b353817",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(xdatade, ydatade, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7396e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.2213 - mse: 1.2213 - val_loss: 0.8478 - val_mse: 0.8478\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.0342 - mse: 1.0342 - val_loss: 0.8316 - val_mse: 0.8316\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.9773 - mse: 0.9773 - val_loss: 0.8270 - val_mse: 0.8270\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.9278 - mse: 0.9278 - val_loss: 0.8235 - val_mse: 0.8235\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.9131 - mse: 0.9131 - val_loss: 0.8321 - val_mse: 0.8321\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8597 - mse: 0.8597 - val_loss: 0.8571 - val_mse: 0.8571\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.8301 - mse: 0.8301 - val_loss: 0.8323 - val_mse: 0.8323\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.8256 - mse: 0.8256 - val_loss: 0.8516 - val_mse: 0.8516\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7751 - mse: 0.7751 - val_loss: 0.8596 - val_mse: 0.8596\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7482 - mse: 0.7482 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7426 - mse: 0.7426 - val_loss: 0.9319 - val_mse: 0.9319\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7138 - mse: 0.7138 - val_loss: 0.9170 - val_mse: 0.9170\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6777 - mse: 0.6777 - val_loss: 0.9494 - val_mse: 0.9494\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6482 - mse: 0.6482 - val_loss: 0.9474 - val_mse: 0.9474\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6290 - mse: 0.6290 - val_loss: 1.0820 - val_mse: 1.0820\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6061 - mse: 0.6061 - val_loss: 1.0336 - val_mse: 1.0336\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5885 - mse: 0.5885 - val_loss: 0.9707 - val_mse: 0.9707\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5916 - mse: 0.5916 - val_loss: 1.1213 - val_mse: 1.1213\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5473 - mse: 0.5473 - val_loss: 1.1430 - val_mse: 1.1430\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5251 - mse: 0.5251 - val_loss: 1.1300 - val_mse: 1.1300\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4950 - mse: 0.4950 - val_loss: 1.2229 - val_mse: 1.2229\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4627 - mse: 0.4627 - val_loss: 1.2462 - val_mse: 1.2462\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4368 - mse: 0.4368 - val_loss: 1.2648 - val_mse: 1.2648\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4215 - mse: 0.4215 - val_loss: 1.5074 - val_mse: 1.5074\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4022 - mse: 0.4022 - val_loss: 1.3637 - val_mse: 1.3637\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3758 - mse: 0.3758 - val_loss: 1.3452 - val_mse: 1.3452\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3579 - mse: 0.3579 - val_loss: 1.4714 - val_mse: 1.4714\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3431 - mse: 0.3431 - val_loss: 1.6274 - val_mse: 1.6274\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3336 - mse: 0.3336 - val_loss: 1.4948 - val_mse: 1.4948\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3071 - mse: 0.3071 - val_loss: 1.6403 - val_mse: 1.6403\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2946 - mse: 0.2946 - val_loss: 1.4742 - val_mse: 1.4742\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2768 - mse: 0.2768 - val_loss: 1.6242 - val_mse: 1.6242\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2573 - mse: 0.2573 - val_loss: 1.6331 - val_mse: 1.6331\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2641 - mse: 0.2641 - val_loss: 1.5788 - val_mse: 1.5788\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2545 - mse: 0.2545 - val_loss: 1.8521 - val_mse: 1.8521\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2373 - mse: 0.2373 - val_loss: 1.7429 - val_mse: 1.7429\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2161 - mse: 0.2161 - val_loss: 1.8889 - val_mse: 1.8889\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2132 - mse: 0.2132 - val_loss: 1.8030 - val_mse: 1.8030\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1851 - mse: 0.1851 - val_loss: 1.7463 - val_mse: 1.7463\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1938 - mse: 0.1938 - val_loss: 1.7081 - val_mse: 1.7081\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1746 - mse: 0.1746 - val_loss: 1.7137 - val_mse: 1.7137\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1669 - mse: 0.1669 - val_loss: 1.7159 - val_mse: 1.7159\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1592 - mse: 0.1592 - val_loss: 1.8439 - val_mse: 1.8439\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1555 - mse: 0.1555 - val_loss: 1.7796 - val_mse: 1.7796\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1343 - mse: 0.1343 - val_loss: 1.7765 - val_mse: 1.7765\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1366 - mse: 0.1366 - val_loss: 1.6831 - val_mse: 1.6831\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1269 - mse: 0.1269 - val_loss: 1.7671 - val_mse: 1.7671\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1211 - mse: 0.1211 - val_loss: 1.7263 - val_mse: 1.7263\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1364 - mse: 0.1364 - val_loss: 1.7384 - val_mse: 1.7384\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 1.8758 - val_mse: 1.8758\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 1.9028 - val_mse: 1.9028\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1025 - mse: 0.1025 - val_loss: 1.8737 - val_mse: 1.8737\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 1.8884 - val_mse: 1.8884\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 2.0848 - val_mse: 2.0848\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0771 - mse: 0.0771 - val_loss: 1.9297 - val_mse: 1.9297\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 2.0419 - val_mse: 2.0419\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0731 - mse: 0.0731 - val_loss: 2.2074 - val_mse: 2.2074\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0749 - mse: 0.0749 - val_loss: 2.1434 - val_mse: 2.1434\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 2.0433 - val_mse: 2.0433\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 1.9465 - val_mse: 1.9465\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0789 - mse: 0.0789 - val_loss: 1.9981 - val_mse: 1.9981\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 2.1862 - val_mse: 2.1862\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0663 - mse: 0.0663 - val_loss: 1.9936 - val_mse: 1.9936\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 2.0146 - val_mse: 2.0146\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 2.0772 - val_mse: 2.0772\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 2.0539 - val_mse: 2.0539\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 2.0604 - val_mse: 2.0604\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 2.1840 - val_mse: 2.1840\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 2.1541 - val_mse: 2.1541\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 2.0277 - val_mse: 2.0277\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 2.0053 - val_mse: 2.0053\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 2.0396 - val_mse: 2.0396\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 1.9478 - val_mse: 1.9478\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0640 - mse: 0.0640 - val_loss: 2.0569 - val_mse: 2.0569\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 2.0605 - val_mse: 2.0605\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 2.1688 - val_mse: 2.1688\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 2.0560 - val_mse: 2.0560\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 2.0131 - val_mse: 2.0131\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 2.0833 - val_mse: 2.0833\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 2.1101 - val_mse: 2.1101\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 2.2053 - val_mse: 2.2053\n",
      "Epoch 82/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 2.2391 - val_mse: 2.2391\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 2.2484 - val_mse: 2.2484\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 2.1507 - val_mse: 2.1507\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 2.1568 - val_mse: 2.1568\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 2.2937 - val_mse: 2.2937\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 2.1970 - val_mse: 2.1970\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 2.2485 - val_mse: 2.2485\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 2.2539 - val_mse: 2.2539\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 2.1639 - val_mse: 2.1639\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 2.2429 - val_mse: 2.2429\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 2.2559 - val_mse: 2.2559\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 2.2437 - val_mse: 2.2437\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 2.3201 - val_mse: 2.3201\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 2.3421 - val_mse: 2.3421\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 2.3112 - val_mse: 2.3112\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 2.2559 - val_mse: 2.2559\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 2.3303 - val_mse: 2.3303\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 2.2992 - val_mse: 2.2992\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 2.3507 - val_mse: 2.3507\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 2.3227 - val_mse: 2.3227\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 2.3739 - val_mse: 2.3739\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 2.2877 - val_mse: 2.2877\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 2.3820 - val_mse: 2.3820\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 2.4023 - val_mse: 2.4023\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 2.3379 - val_mse: 2.3379\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 2.3426 - val_mse: 2.3426\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 2.3835 - val_mse: 2.3835\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 2.3978 - val_mse: 2.3978\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 2.4025 - val_mse: 2.4025\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 2.3742 - val_mse: 2.3742\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 2.3225 - val_mse: 2.3225\n",
      "Epoch 113/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 2.3810 - val_mse: 2.3810\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 2.4102 - val_mse: 2.4102\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 2.3838 - val_mse: 2.3838\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 2.3455 - val_mse: 2.3455\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 2.4166 - val_mse: 2.4166\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 2.4297 - val_mse: 2.4297\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 2.3483 - val_mse: 2.3483\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 2.4013 - val_mse: 2.4013\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 2.4095 - val_mse: 2.4095\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.4355 - val_mse: 2.4355\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 2.4277 - val_mse: 2.4277\n",
      "Epoch 124/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.4032 - val_mse: 2.4032\n",
      "Epoch 125/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.4647 - val_mse: 2.4647\n",
      "Epoch 126/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.4087 - val_mse: 2.4087\n",
      "Epoch 127/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 2.4061 - val_mse: 2.4061\n",
      "Epoch 128/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 2.4490 - val_mse: 2.4490\n",
      "Epoch 129/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 2.3414 - val_mse: 2.3414\n",
      "Epoch 130/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 2.4291 - val_mse: 2.4291\n",
      "Epoch 131/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.3854 - val_mse: 2.3854\n",
      "Epoch 132/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.4155 - val_mse: 2.4155\n",
      "Epoch 133/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.3938 - val_mse: 2.3938\n",
      "Epoch 134/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.4374 - val_mse: 2.4374\n",
      "Epoch 135/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.4306 - val_mse: 2.4306\n",
      "Epoch 136/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 2.3593 - val_mse: 2.3593\n",
      "Epoch 137/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.5042 - val_mse: 2.5042\n",
      "Epoch 138/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 2.4472 - val_mse: 2.4472\n",
      "Epoch 139/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.4222 - val_mse: 2.4222\n",
      "Epoch 140/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.4633 - val_mse: 2.4633\n",
      "Epoch 141/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 2.4268 - val_mse: 2.4268\n",
      "Epoch 142/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.3973 - val_mse: 2.3973\n",
      "Epoch 143/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.4317 - val_mse: 2.4317\n",
      "Epoch 144/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 2.3989 - val_mse: 2.3989\n",
      "Epoch 145/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.4561 - val_mse: 2.4561\n",
      "Epoch 146/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.4435 - val_mse: 2.4435\n",
      "Epoch 147/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 2.3784 - val_mse: 2.3784\n",
      "Epoch 148/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 2.4864 - val_mse: 2.4864\n",
      "Epoch 149/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 2.4263 - val_mse: 2.4263\n",
      "Epoch 150/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 2.3944 - val_mse: 2.3944\n",
      "Epoch 151/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.4614 - val_mse: 2.4614\n",
      "Epoch 152/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 2.3649 - val_mse: 2.3649\n",
      "Epoch 153/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.4407 - val_mse: 2.4407\n",
      "Epoch 154/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.4161 - val_mse: 2.4161\n",
      "Epoch 155/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 2.4193 - val_mse: 2.4193\n",
      "Epoch 156/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 2.3826 - val_mse: 2.3826\n",
      "Epoch 157/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 2.3075 - val_mse: 2.3075\n",
      "Epoch 158/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 2.4671 - val_mse: 2.4671\n",
      "Epoch 159/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 2.3149 - val_mse: 2.3149\n",
      "Epoch 160/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 2.3749 - val_mse: 2.3749\n",
      "Epoch 161/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 2.2935 - val_mse: 2.2935\n",
      "Epoch 162/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 2.4981 - val_mse: 2.4981\n",
      "Epoch 163/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 2.5053 - val_mse: 2.5053\n",
      "Epoch 164/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 2.3676 - val_mse: 2.3676\n",
      "Epoch 165/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 2.5649 - val_mse: 2.5649\n",
      "Epoch 166/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 2.4551 - val_mse: 2.4551\n",
      "Epoch 167/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 2.2975 - val_mse: 2.2975\n",
      "Epoch 168/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 2.4030 - val_mse: 2.4030\n",
      "Epoch 169/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 2.3619 - val_mse: 2.3619\n",
      "Epoch 170/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 2.3569 - val_mse: 2.3569\n",
      "Epoch 171/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 2.5277 - val_mse: 2.5277\n",
      "Epoch 172/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 2.4516 - val_mse: 2.4516\n",
      "Epoch 173/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 2.3873 - val_mse: 2.3873\n",
      "Epoch 174/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 2.2310 - val_mse: 2.2310\n",
      "Epoch 175/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 2.3507 - val_mse: 2.3507\n",
      "Epoch 176/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 2.5321 - val_mse: 2.5321\n",
      "Epoch 177/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 2.3367 - val_mse: 2.3367\n",
      "Epoch 178/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 2.1424 - val_mse: 2.1424\n",
      "Epoch 179/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 2.3040 - val_mse: 2.3040\n",
      "Epoch 180/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 2.2243 - val_mse: 2.2243\n",
      "Epoch 181/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 2.2492 - val_mse: 2.2492\n",
      "Epoch 182/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 2.2482 - val_mse: 2.2482\n",
      "Epoch 183/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 2.2543 - val_mse: 2.2543\n",
      "Epoch 184/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 2.4167 - val_mse: 2.4167\n",
      "Epoch 185/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 2.2378 - val_mse: 2.2378\n",
      "Epoch 186/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 2.4925 - val_mse: 2.4925\n",
      "Epoch 187/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 2.2691 - val_mse: 2.2691\n",
      "Epoch 188/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 2.2909 - val_mse: 2.2909\n",
      "Epoch 189/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 2.3883 - val_mse: 2.3883\n",
      "Epoch 190/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 2.3162 - val_mse: 2.3162\n",
      "Epoch 191/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.3235 - val_mse: 2.3235\n",
      "Epoch 192/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 2.4054 - val_mse: 2.4054\n",
      "Epoch 193/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 2.2567 - val_mse: 2.2567\n",
      "Epoch 194/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 2.4454 - val_mse: 2.4454\n",
      "Epoch 195/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 2.2614 - val_mse: 2.2614\n",
      "Epoch 196/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 2.3674 - val_mse: 2.3674\n",
      "Epoch 197/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 2.2968 - val_mse: 2.2968\n",
      "Epoch 198/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.2811 - val_mse: 2.2811\n",
      "Epoch 199/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.3088 - val_mse: 2.3088\n",
      "Epoch 200/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 2.3625 - val_mse: 2.3625\n",
      "Epoch 201/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 2.2904 - val_mse: 2.2904\n",
      "Epoch 202/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.3565 - val_mse: 2.3565\n",
      "Epoch 203/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 2.3011 - val_mse: 2.3011\n",
      "Epoch 204/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 2.3499 - val_mse: 2.3499\n",
      "Epoch 205/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.7139e-04 - mse: 8.7139e-04 - val_loss: 2.3635 - val_mse: 2.3635\n",
      "Epoch 206/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.5952e-04 - mse: 9.5952e-04 - val_loss: 2.3367 - val_mse: 2.3367\n",
      "Epoch 207/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.0487e-04 - mse: 9.0487e-04 - val_loss: 2.3356 - val_mse: 2.3356\n",
      "Epoch 208/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.3016e-04 - mse: 6.3016e-04 - val_loss: 2.3320 - val_mse: 2.3320\n",
      "Epoch 209/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.4277e-04 - mse: 5.4277e-04 - val_loss: 2.3310 - val_mse: 2.3310\n",
      "Epoch 210/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.8632e-04 - mse: 7.8632e-04 - val_loss: 2.3319 - val_mse: 2.3319\n",
      "Epoch 211/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.4518e-04 - mse: 9.4518e-04 - val_loss: 2.3358 - val_mse: 2.3358\n",
      "Epoch 212/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 2.3683 - val_mse: 2.3683\n",
      "Epoch 213/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 2.3475 - val_mse: 2.3475\n",
      "Epoch 214/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 2.3395 - val_mse: 2.3395\n",
      "Epoch 215/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.5054e-04 - mse: 9.5054e-04 - val_loss: 2.3378 - val_mse: 2.3378\n",
      "Epoch 216/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 2.3224 - val_mse: 2.3224\n",
      "Epoch 217/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 2.3279 - val_mse: 2.3279\n",
      "Epoch 218/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 2.3395 - val_mse: 2.3395\n",
      "Epoch 219/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 2.3624 - val_mse: 2.3624\n",
      "Epoch 220/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 2.3220 - val_mse: 2.3220\n",
      "Epoch 221/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.3474 - val_mse: 2.3474\n",
      "Epoch 222/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.3094 - val_mse: 2.3094\n",
      "Epoch 223/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.3705 - val_mse: 2.3705\n",
      "Epoch 224/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.3387 - val_mse: 2.3387\n",
      "Epoch 225/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 2.3847 - val_mse: 2.3847\n",
      "Epoch 226/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.2930 - val_mse: 2.2930\n",
      "Epoch 227/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 2.2621 - val_mse: 2.2621\n",
      "Epoch 228/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 2.3264 - val_mse: 2.3264\n",
      "Epoch 229/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 2.4038 - val_mse: 2.4038\n",
      "Epoch 230/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 2.2676 - val_mse: 2.2676\n",
      "Epoch 231/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 2.3881 - val_mse: 2.3881\n",
      "Epoch 232/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 2.1651 - val_mse: 2.1651\n",
      "Epoch 233/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 2.3672 - val_mse: 2.3672\n",
      "Epoch 234/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 2.4126 - val_mse: 2.4126\n",
      "Epoch 235/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 2.4965 - val_mse: 2.4965\n",
      "Epoch 236/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 2.1756 - val_mse: 2.1756\n",
      "Epoch 237/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 2.4246 - val_mse: 2.4246\n",
      "Epoch 238/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 2.4315 - val_mse: 2.4315\n",
      "Epoch 239/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 2.3172 - val_mse: 2.3172\n",
      "Epoch 240/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 2.3984 - val_mse: 2.3984\n",
      "Epoch 241/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 2.2566 - val_mse: 2.2566\n",
      "Epoch 242/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 2.4535 - val_mse: 2.4535\n",
      "Epoch 243/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 2.2467 - val_mse: 2.2467\n",
      "Epoch 244/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 2.1569 - val_mse: 2.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 2.4687 - val_mse: 2.4687\n",
      "Epoch 246/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 2.2100 - val_mse: 2.2100\n",
      "Epoch 247/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 2.5943 - val_mse: 2.5943\n",
      "Epoch 248/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 2.0977 - val_mse: 2.0977\n",
      "Epoch 249/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 2.5399 - val_mse: 2.5399\n",
      "Epoch 250/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 1.8228 - val_mse: 1.8228\n",
      "Epoch 251/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 2.3756 - val_mse: 2.3756\n",
      "Epoch 252/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 2.0773 - val_mse: 2.0773\n",
      "Epoch 253/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 2.3336 - val_mse: 2.3336\n",
      "Epoch 254/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 2.0501 - val_mse: 2.0501\n",
      "Epoch 255/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0648 - mse: 0.0648 - val_loss: 1.9977 - val_mse: 1.9977\n",
      "Epoch 256/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 2.0986 - val_mse: 2.0986\n",
      "Epoch 257/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 2.2770 - val_mse: 2.2770\n",
      "Epoch 258/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 2.2020 - val_mse: 2.2020\n",
      "Epoch 259/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 2.2314 - val_mse: 2.2314\n",
      "Epoch 260/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 2.1841 - val_mse: 2.1841\n",
      "Epoch 261/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.2810 - val_mse: 2.2810\n",
      "Epoch 262/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.2389 - val_mse: 2.2389\n",
      "Epoch 263/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 2.2663 - val_mse: 2.2663\n",
      "Epoch 264/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 2.2492 - val_mse: 2.2492\n",
      "Epoch 265/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 2.2733 - val_mse: 2.2733\n",
      "Epoch 266/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 2.2570 - val_mse: 2.2570\n",
      "Epoch 267/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 2.3188 - val_mse: 2.3188\n",
      "Epoch 268/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 2.2634 - val_mse: 2.2634\n",
      "Epoch 269/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.1836e-04 - mse: 9.1836e-04 - val_loss: 2.2992 - val_mse: 2.2992\n",
      "Epoch 270/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.7052e-04 - mse: 9.7052e-04 - val_loss: 2.2768 - val_mse: 2.2768\n",
      "Epoch 271/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.8688e-04 - mse: 6.8688e-04 - val_loss: 2.2751 - val_mse: 2.2751\n",
      "Epoch 272/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.2097e-04 - mse: 4.2097e-04 - val_loss: 2.2742 - val_mse: 2.2742\n",
      "Epoch 273/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.1069e-04 - mse: 4.1069e-04 - val_loss: 2.2639 - val_mse: 2.2639\n",
      "Epoch 274/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.6104e-04 - mse: 3.6104e-04 - val_loss: 2.2644 - val_mse: 2.2644\n",
      "Epoch 275/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.2870e-04 - mse: 4.2870e-04 - val_loss: 2.2904 - val_mse: 2.2904\n",
      "Epoch 276/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 2.2489 - val_mse: 2.2489\n",
      "Epoch 277/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.1246e-04 - mse: 8.1246e-04 - val_loss: 2.2565 - val_mse: 2.2565\n",
      "Epoch 278/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.2341e-04 - mse: 5.2341e-04 - val_loss: 2.2832 - val_mse: 2.2832\n",
      "Epoch 279/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.6544e-04 - mse: 8.6544e-04 - val_loss: 2.2244 - val_mse: 2.2244\n",
      "Epoch 280/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.9606e-04 - mse: 7.9606e-04 - val_loss: 2.3126 - val_mse: 2.3126\n",
      "Epoch 281/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.3353e-04 - mse: 7.3353e-04 - val_loss: 2.2565 - val_mse: 2.2565\n",
      "Epoch 282/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.9962e-04 - mse: 4.9962e-04 - val_loss: 2.2829 - val_mse: 2.2829\n",
      "Epoch 283/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.6249e-04 - mse: 4.6249e-04 - val_loss: 2.2684 - val_mse: 2.2684\n",
      "Epoch 284/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.5436e-04 - mse: 3.5436e-04 - val_loss: 2.2657 - val_mse: 2.2657\n",
      "Epoch 285/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.7321e-04 - mse: 3.7321e-04 - val_loss: 2.2679 - val_mse: 2.2679\n",
      "Epoch 286/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.2010e-04 - mse: 3.2010e-04 - val_loss: 2.2753 - val_mse: 2.2753\n",
      "Epoch 287/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.7058e-04 - mse: 2.7058e-04 - val_loss: 2.2448 - val_mse: 2.2448\n",
      "Epoch 288/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.1426e-04 - mse: 2.1426e-04 - val_loss: 2.2762 - val_mse: 2.2762\n",
      "Epoch 289/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.4663e-04 - mse: 1.4663e-04 - val_loss: 2.2580 - val_mse: 2.2580\n",
      "Epoch 290/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.3601e-04 - mse: 1.3601e-04 - val_loss: 2.2838 - val_mse: 2.2838\n",
      "Epoch 291/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.4509e-04 - mse: 1.4509e-04 - val_loss: 2.2794 - val_mse: 2.2794\n",
      "Epoch 292/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.1940e-04 - mse: 1.1940e-04 - val_loss: 2.2695 - val_mse: 2.2695\n",
      "Epoch 293/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.7448e-05 - mse: 9.7448e-05 - val_loss: 2.2780 - val_mse: 2.2780\n",
      "Epoch 294/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.5832e-05 - mse: 7.5832e-05 - val_loss: 2.2665 - val_mse: 2.2665\n",
      "Epoch 295/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.0371e-04 - mse: 1.0371e-04 - val_loss: 2.2682 - val_mse: 2.2682\n",
      "Epoch 296/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.2288e-05 - mse: 9.2288e-05 - val_loss: 2.2801 - val_mse: 2.2801\n",
      "Epoch 297/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.5716e-04 - mse: 5.5716e-04 - val_loss: 2.2964 - val_mse: 2.2964\n",
      "Epoch 298/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.6351e-04 - mse: 4.6351e-04 - val_loss: 2.2680 - val_mse: 2.2680\n",
      "Epoch 299/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.3425e-04 - mse: 3.3425e-04 - val_loss: 2.2606 - val_mse: 2.2606\n",
      "Epoch 300/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 2.2913 - val_mse: 2.2913\n",
      "Epoch 301/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 2.2634 - val_mse: 2.2634\n",
      "Epoch 302/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 2.1825 - val_mse: 2.1825\n",
      "Epoch 303/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 2.2258 - val_mse: 2.2258\n",
      "Epoch 304/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 2.2306 - val_mse: 2.2306\n",
      "Epoch 305/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 2.2017 - val_mse: 2.2017\n",
      "Epoch 306/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 2.2144 - val_mse: 2.2144\n",
      "Epoch 307/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 2.2831 - val_mse: 2.2831\n",
      "Epoch 308/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 2.1891 - val_mse: 2.1891\n",
      "Epoch 309/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.1990 - val_mse: 2.1990\n",
      "Epoch 310/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.2017 - val_mse: 2.2017\n",
      "Epoch 311/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.1347 - val_mse: 2.1347\n",
      "Epoch 312/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.2791 - val_mse: 2.2791\n",
      "Epoch 313/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.2287 - val_mse: 2.2287\n",
      "Epoch 314/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 2.2183 - val_mse: 2.2183\n",
      "Epoch 315/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.2269 - val_mse: 2.2269\n",
      "Epoch 316/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 2.2369 - val_mse: 2.2369\n",
      "Epoch 317/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 2.2548 - val_mse: 2.2548\n",
      "Epoch 318/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.2177 - val_mse: 2.2177\n",
      "Epoch 319/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 2.2437 - val_mse: 2.2437\n",
      "Epoch 320/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 2.2451 - val_mse: 2.2451\n",
      "Epoch 321/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 2.1770 - val_mse: 2.1770\n",
      "Epoch 322/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 2.1778 - val_mse: 2.1778\n",
      "Epoch 323/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.2059 - val_mse: 2.2059\n",
      "Epoch 324/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.2166 - val_mse: 2.2166\n",
      "Epoch 325/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.2479 - val_mse: 2.2479\n",
      "Epoch 326/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 2.1522 - val_mse: 2.1522\n",
      "Epoch 327/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 2.2270 - val_mse: 2.2270\n",
      "Epoch 328/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 2.2042 - val_mse: 2.2042\n",
      "Epoch 329/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.1267 - val_mse: 2.1267\n",
      "Epoch 330/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.2081 - val_mse: 2.2081\n",
      "Epoch 331/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 2.1173 - val_mse: 2.1173\n",
      "Epoch 332/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.1523 - val_mse: 2.1523\n",
      "Epoch 333/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.2648 - val_mse: 2.2648\n",
      "Epoch 334/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 2.0482 - val_mse: 2.0482\n",
      "Epoch 335/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 2.3528 - val_mse: 2.3528\n",
      "Epoch 336/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 2.0946 - val_mse: 2.0946\n",
      "Epoch 337/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 2.1033 - val_mse: 2.1033\n",
      "Epoch 338/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 1.9878 - val_mse: 1.9878\n",
      "Epoch 339/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 2.2374 - val_mse: 2.2374\n",
      "Epoch 340/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 2.0944 - val_mse: 2.0944\n",
      "Epoch 341/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 2.1322 - val_mse: 2.1322\n",
      "Epoch 342/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 1.9594 - val_mse: 1.9594\n",
      "Epoch 343/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 2.1906 - val_mse: 2.1906\n",
      "Epoch 344/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 2.0532 - val_mse: 2.0532\n",
      "Epoch 345/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 2.0213 - val_mse: 2.0213\n",
      "Epoch 346/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 2.0081 - val_mse: 2.0081\n",
      "Epoch 347/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 2.0104 - val_mse: 2.0104\n",
      "Epoch 348/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 2.1152 - val_mse: 2.1152\n",
      "Epoch 349/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 2.1042 - val_mse: 2.1042\n",
      "Epoch 350/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 1.9552 - val_mse: 1.9552\n",
      "Epoch 351/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 2.0253 - val_mse: 2.0253\n",
      "Epoch 352/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 2.0238 - val_mse: 2.0238\n",
      "Epoch 353/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 2.1206 - val_mse: 2.1206\n",
      "Epoch 354/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 2.0170 - val_mse: 2.0170\n",
      "Epoch 355/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 1.9100 - val_mse: 1.9100\n",
      "Epoch 356/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 2.1107 - val_mse: 2.1107\n",
      "Epoch 357/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 1.7922 - val_mse: 1.7922\n",
      "Epoch 358/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 1.9729 - val_mse: 1.9729\n",
      "Epoch 359/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 1.9198 - val_mse: 1.9198\n",
      "Epoch 360/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 1.9166 - val_mse: 1.9166\n",
      "Epoch 361/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 1.8421 - val_mse: 1.8421\n",
      "Epoch 362/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 1.8735 - val_mse: 1.8735\n",
      "Epoch 363/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 1.9975 - val_mse: 1.9975\n",
      "Epoch 364/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 1.9435 - val_mse: 1.9435\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 1.8600 - val_mse: 1.8600\n",
      "Epoch 366/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.8598 - val_mse: 1.8598\n",
      "Epoch 367/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 1.9727 - val_mse: 1.9727\n",
      "Epoch 368/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 2.1417 - val_mse: 2.1417\n",
      "Epoch 369/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 2.0395 - val_mse: 2.0395\n",
      "Epoch 370/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 1.8509 - val_mse: 1.8509\n",
      "Epoch 371/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 1.9264 - val_mse: 1.9264\n",
      "Epoch 372/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 1.9054 - val_mse: 1.9054\n",
      "Epoch 373/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 1.8920 - val_mse: 1.8920\n",
      "Epoch 374/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 1.9380 - val_mse: 1.9380\n",
      "Epoch 375/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.8833 - val_mse: 1.8833\n",
      "Epoch 376/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.9164 - val_mse: 1.9164\n",
      "Epoch 377/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.9642 - val_mse: 1.9642\n",
      "Epoch 378/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.8869 - val_mse: 1.8869\n",
      "Epoch 379/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.9208 - val_mse: 1.9208\n",
      "Epoch 380/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.9486 - val_mse: 1.9486\n",
      "Epoch 381/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.9072 - val_mse: 1.9072\n",
      "Epoch 382/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 1.8970 - val_mse: 1.8970\n",
      "Epoch 383/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 1.8532 - val_mse: 1.8532\n",
      "Epoch 384/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 1.8777 - val_mse: 1.8777\n",
      "Epoch 385/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 1.9733 - val_mse: 1.9733\n",
      "Epoch 386/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 1.7952 - val_mse: 1.7952\n",
      "Epoch 387/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 2.0144 - val_mse: 2.0144\n",
      "Epoch 388/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 1.8139 - val_mse: 1.8139\n",
      "Epoch 389/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 1.8504 - val_mse: 1.8504\n",
      "Epoch 390/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 1.9109 - val_mse: 1.9109\n",
      "Epoch 391/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.8267 - val_mse: 1.8267\n",
      "Epoch 392/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 1.8732 - val_mse: 1.8732\n",
      "Epoch 393/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 1.9292 - val_mse: 1.9292\n",
      "Epoch 394/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 1.9281 - val_mse: 1.9281\n",
      "Epoch 395/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.8674 - val_mse: 1.8674\n",
      "Epoch 396/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.8541 - val_mse: 1.8541\n",
      "Epoch 397/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.8623 - val_mse: 1.8623\n",
      "Epoch 398/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.8844 - val_mse: 1.8844\n",
      "Epoch 399/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.6452e-04 - mse: 8.6452e-04 - val_loss: 1.8981 - val_mse: 1.8981\n",
      "Epoch 400/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.2193e-04 - mse: 5.2193e-04 - val_loss: 1.8626 - val_mse: 1.8626\n",
      "Epoch 401/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.7882e-04 - mse: 4.7882e-04 - val_loss: 1.8782 - val_mse: 1.8782\n",
      "Epoch 402/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.9543e-04 - mse: 3.9543e-04 - val_loss: 1.8831 - val_mse: 1.8831\n",
      "Epoch 403/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.0523e-04 - mse: 3.0523e-04 - val_loss: 1.8721 - val_mse: 1.8721\n",
      "Epoch 404/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.7191e-04 - mse: 6.7191e-04 - val_loss: 1.8965 - val_mse: 1.8965\n",
      "Epoch 405/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.5587e-04 - mse: 5.5587e-04 - val_loss: 1.8437 - val_mse: 1.8437\n",
      "Epoch 406/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.7756e-04 - mse: 4.7756e-04 - val_loss: 1.9052 - val_mse: 1.9052\n",
      "Epoch 407/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.9250e-04 - mse: 5.9250e-04 - val_loss: 1.8688 - val_mse: 1.8688\n",
      "Epoch 408/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.7922e-04 - mse: 7.7922e-04 - val_loss: 1.8365 - val_mse: 1.8365\n",
      "Epoch 409/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.5269e-04 - mse: 7.5269e-04 - val_loss: 1.8874 - val_mse: 1.8874\n",
      "Epoch 410/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.7290e-04 - mse: 4.7290e-04 - val_loss: 1.8544 - val_mse: 1.8544\n",
      "Epoch 411/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.1656e-04 - mse: 3.1656e-04 - val_loss: 1.8478 - val_mse: 1.8478\n",
      "Epoch 412/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.9615e-04 - mse: 3.9615e-04 - val_loss: 1.8851 - val_mse: 1.8851\n",
      "Epoch 413/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.9869e-04 - mse: 2.9869e-04 - val_loss: 1.8439 - val_mse: 1.8439\n",
      "Epoch 414/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.0028e-04 - mse: 3.0028e-04 - val_loss: 1.8799 - val_mse: 1.8799\n",
      "Epoch 415/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.7790e-04 - mse: 8.7790e-04 - val_loss: 1.8467 - val_mse: 1.8467\n",
      "Epoch 416/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.9069e-04 - mse: 5.9069e-04 - val_loss: 1.8750 - val_mse: 1.8750\n",
      "Epoch 417/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.1886e-04 - mse: 6.1886e-04 - val_loss: 1.8758 - val_mse: 1.8758\n",
      "Epoch 418/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.0546e-04 - mse: 9.0546e-04 - val_loss: 1.8584 - val_mse: 1.8584\n",
      "Epoch 419/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.8629 - val_mse: 1.8629\n",
      "Epoch 420/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.8808 - val_mse: 1.8808\n",
      "Epoch 421/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.8250 - val_mse: 1.8250\n",
      "Epoch 422/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.9160 - val_mse: 1.9160\n",
      "Epoch 423/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.8277 - val_mse: 1.8277\n",
      "Epoch 424/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.9175 - val_mse: 1.9175\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.7837 - val_mse: 1.7837\n",
      "Epoch 426/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.8940 - val_mse: 1.8940\n",
      "Epoch 427/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.8364 - val_mse: 1.8364\n",
      "Epoch 428/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 1.7343 - val_mse: 1.7343\n",
      "Epoch 429/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 1.9284 - val_mse: 1.9284\n",
      "Epoch 430/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 1.8870 - val_mse: 1.8870\n",
      "Epoch 431/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 1.7847 - val_mse: 1.7847\n",
      "Epoch 432/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 1.9344 - val_mse: 1.9344\n",
      "Epoch 433/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 1.8036 - val_mse: 1.8036\n",
      "Epoch 434/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 2.0986 - val_mse: 2.0986\n",
      "Epoch 435/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 1.8200 - val_mse: 1.8200\n",
      "Epoch 436/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 1.9261 - val_mse: 1.9261\n",
      "Epoch 437/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 1.8577 - val_mse: 1.8577\n",
      "Epoch 438/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 1.9220 - val_mse: 1.9220\n",
      "Epoch 439/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 1.6682 - val_mse: 1.6682\n",
      "Epoch 440/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 1.7367 - val_mse: 1.7367\n",
      "Epoch 441/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 1.7669 - val_mse: 1.7669\n",
      "Epoch 442/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 1.8851 - val_mse: 1.8851\n",
      "Epoch 443/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 1.6432 - val_mse: 1.6432\n",
      "Epoch 444/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 1.8628 - val_mse: 1.8628\n",
      "Epoch 445/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 1.6593 - val_mse: 1.6593\n",
      "Epoch 446/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 1.8766 - val_mse: 1.8766\n",
      "Epoch 447/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 1.7687 - val_mse: 1.7687\n",
      "Epoch 448/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 1.8762 - val_mse: 1.8762\n",
      "Epoch 449/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 1.7705 - val_mse: 1.7705\n",
      "Epoch 450/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.8346 - val_mse: 1.8346\n",
      "Epoch 451/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.8090 - val_mse: 1.8090\n",
      "Epoch 452/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.8032 - val_mse: 1.8032\n",
      "Epoch 453/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.7870 - val_mse: 1.7870\n",
      "Epoch 454/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.8153 - val_mse: 1.8153\n",
      "Epoch 455/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.8179 - val_mse: 1.8179\n",
      "Epoch 456/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.8029 - val_mse: 1.8029\n",
      "Epoch 457/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.8462 - val_mse: 1.8462\n",
      "Epoch 458/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.7208 - val_mse: 1.7208\n",
      "Epoch 459/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.8180 - val_mse: 1.8180\n",
      "Epoch 460/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.7989 - val_mse: 1.7989\n",
      "Epoch 461/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.8317 - val_mse: 1.8317\n",
      "Epoch 462/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 8.5563e-04 - mse: 8.5563e-04 - val_loss: 1.7638 - val_mse: 1.7638\n",
      "Epoch 463/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.8063 - val_mse: 1.8063\n",
      "Epoch 464/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.8267 - val_mse: 1.8267\n",
      "Epoch 465/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.5144e-04 - mse: 7.5144e-04 - val_loss: 1.8303 - val_mse: 1.8303\n",
      "Epoch 466/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.6721e-04 - mse: 7.6721e-04 - val_loss: 1.7785 - val_mse: 1.7785\n",
      "Epoch 467/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.5761e-04 - mse: 6.5761e-04 - val_loss: 1.8636 - val_mse: 1.8636\n",
      "Epoch 468/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.2819e-04 - mse: 8.2819e-04 - val_loss: 1.7627 - val_mse: 1.7627\n",
      "Epoch 469/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.8347 - val_mse: 1.8347\n",
      "Epoch 470/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.1700e-04 - mse: 8.1700e-04 - val_loss: 1.7911 - val_mse: 1.7911\n",
      "Epoch 471/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.3054e-04 - mse: 7.3054e-04 - val_loss: 1.8291 - val_mse: 1.8291\n",
      "Epoch 472/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.8647e-04 - mse: 5.8647e-04 - val_loss: 1.8706 - val_mse: 1.8706\n",
      "Epoch 473/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.7704 - val_mse: 1.7704\n",
      "Epoch 474/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.8437 - val_mse: 1.8437\n",
      "Epoch 475/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.8157 - val_mse: 1.8157\n",
      "Epoch 476/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.9200e-04 - mse: 6.9200e-04 - val_loss: 1.8299 - val_mse: 1.8299\n",
      "Epoch 477/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.2860e-04 - mse: 8.2860e-04 - val_loss: 1.8112 - val_mse: 1.8112\n",
      "Epoch 478/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.9818e-04 - mse: 6.9818e-04 - val_loss: 1.8600 - val_mse: 1.8600\n",
      "Epoch 479/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.9170e-04 - mse: 8.9170e-04 - val_loss: 1.8400 - val_mse: 1.8400\n",
      "Epoch 480/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.7594 - val_mse: 1.7594\n",
      "Epoch 481/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.8774 - val_mse: 1.8774\n",
      "Epoch 482/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.7920 - val_mse: 1.7920\n",
      "Epoch 483/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.8230 - val_mse: 1.8230\n",
      "Epoch 484/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.1679e-04 - mse: 9.1679e-04 - val_loss: 1.8211 - val_mse: 1.8211\n",
      "Epoch 485/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.3667e-04 - mse: 8.3667e-04 - val_loss: 1.8184 - val_mse: 1.8184\n",
      "Epoch 486/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.7391e-04 - mse: 6.7391e-04 - val_loss: 1.8048 - val_mse: 1.8048\n",
      "Epoch 487/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.7860e-04 - mse: 5.7860e-04 - val_loss: 1.8181 - val_mse: 1.8181\n",
      "Epoch 488/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.0927e-04 - mse: 6.0927e-04 - val_loss: 1.7795 - val_mse: 1.7795\n",
      "Epoch 489/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.0477e-04 - mse: 8.0477e-04 - val_loss: 1.8181 - val_mse: 1.8181\n",
      "Epoch 490/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.3721e-04 - mse: 5.3721e-04 - val_loss: 1.7898 - val_mse: 1.7898\n",
      "Epoch 491/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.2713e-04 - mse: 7.2713e-04 - val_loss: 1.8176 - val_mse: 1.8176\n",
      "Epoch 492/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.7177e-04 - mse: 5.7177e-04 - val_loss: 1.7914 - val_mse: 1.7914\n",
      "Epoch 493/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.9721e-04 - mse: 3.9721e-04 - val_loss: 1.8244 - val_mse: 1.8244\n",
      "Epoch 494/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.1118e-04 - mse: 3.1118e-04 - val_loss: 1.8042 - val_mse: 1.8042\n",
      "Epoch 495/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.2288e-04 - mse: 3.2288e-04 - val_loss: 1.8142 - val_mse: 1.8142\n",
      "Epoch 496/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.8192e-04 - mse: 2.8192e-04 - val_loss: 1.8166 - val_mse: 1.8166\n",
      "Epoch 497/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.6994e-04 - mse: 3.6994e-04 - val_loss: 1.8195 - val_mse: 1.8195\n",
      "Epoch 498/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.1627e-04 - mse: 5.1627e-04 - val_loss: 1.8122 - val_mse: 1.8122\n",
      "Epoch 499/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.3246e-04 - mse: 6.3246e-04 - val_loss: 1.7808 - val_mse: 1.7808\n",
      "Epoch 500/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.8086e-04 - mse: 7.8086e-04 - val_loss: 1.7881 - val_mse: 1.7881\n",
      "Epoch 501/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.1194e-04 - mse: 6.1194e-04 - val_loss: 1.8028 - val_mse: 1.8028\n",
      "Epoch 502/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.2068e-04 - mse: 4.2068e-04 - val_loss: 1.7931 - val_mse: 1.7931\n",
      "Epoch 503/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.6096e-04 - mse: 4.6096e-04 - val_loss: 1.7973 - val_mse: 1.7973\n",
      "Epoch 504/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.2856e-04 - mse: 4.2856e-04 - val_loss: 1.8107 - val_mse: 1.8107\n",
      "Epoch 505/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.7309e-04 - mse: 5.7309e-04 - val_loss: 1.8179 - val_mse: 1.8179\n",
      "Epoch 506/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.8783e-04 - mse: 7.8783e-04 - val_loss: 1.8355 - val_mse: 1.8355\n",
      "Epoch 507/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.7982 - val_mse: 1.7982\n",
      "Epoch 508/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.8406 - val_mse: 1.8406\n",
      "Epoch 509/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 1.6459 - val_mse: 1.6459\n",
      "Epoch 510/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 1.7099 - val_mse: 1.7099\n",
      "Epoch 511/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 1.7465 - val_mse: 1.7465\n",
      "Epoch 512/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 1.7553 - val_mse: 1.7553\n",
      "Epoch 513/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 1.7491 - val_mse: 1.7491\n",
      "Epoch 514/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0422 - mse: 0.0422 - val_loss: 1.4999 - val_mse: 1.4999\n",
      "Epoch 515/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 1.9271 - val_mse: 1.9271\n",
      "Epoch 516/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 1.5035 - val_mse: 1.5035\n",
      "Epoch 517/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 2.0002 - val_mse: 2.0002\n",
      "Epoch 518/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 1.4759 - val_mse: 1.4759\n",
      "Epoch 519/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 1.7891 - val_mse: 1.7891\n",
      "Epoch 520/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 1.6779 - val_mse: 1.6779\n",
      "Epoch 521/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 1.7679 - val_mse: 1.7679\n",
      "Epoch 522/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 1.7016 - val_mse: 1.7016\n",
      "Epoch 523/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 1.6253 - val_mse: 1.6253\n",
      "Epoch 524/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.7410 - val_mse: 1.7410\n",
      "Epoch 525/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.6637 - val_mse: 1.6637\n",
      "Epoch 526/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.6922 - val_mse: 1.6922\n",
      "Epoch 527/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.7290 - val_mse: 1.7290\n",
      "Epoch 528/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.5325e-04 - mse: 7.5325e-04 - val_loss: 1.7489 - val_mse: 1.7489\n",
      "Epoch 529/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.4609e-04 - mse: 7.4609e-04 - val_loss: 1.7097 - val_mse: 1.7097\n",
      "Epoch 530/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.6768e-04 - mse: 7.6768e-04 - val_loss: 1.7035 - val_mse: 1.7035\n",
      "Epoch 531/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.1479e-04 - mse: 7.1479e-04 - val_loss: 1.7235 - val_mse: 1.7235\n",
      "Epoch 532/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.6139e-04 - mse: 8.6139e-04 - val_loss: 1.7173 - val_mse: 1.7173\n",
      "Epoch 533/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.5117e-04 - mse: 9.5117e-04 - val_loss: 1.7297 - val_mse: 1.7297\n",
      "Epoch 534/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.5974e-04 - mse: 9.5974e-04 - val_loss: 1.7355 - val_mse: 1.7355\n",
      "Epoch 535/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.6940 - val_mse: 1.6940\n",
      "Epoch 536/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.1883e-04 - mse: 9.1883e-04 - val_loss: 1.7633 - val_mse: 1.7633\n",
      "Epoch 537/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.7096 - val_mse: 1.7096\n",
      "Epoch 538/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.7395 - val_mse: 1.7395\n",
      "Epoch 539/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.7091 - val_mse: 1.7091\n",
      "Epoch 540/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.9805e-04 - mse: 9.9805e-04 - val_loss: 1.7320 - val_mse: 1.7320\n",
      "Epoch 541/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.6441e-04 - mse: 5.6441e-04 - val_loss: 1.7257 - val_mse: 1.7257\n",
      "Epoch 542/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.1799e-04 - mse: 6.1799e-04 - val_loss: 1.7250 - val_mse: 1.7250\n",
      "Epoch 543/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 4.8093e-04 - mse: 4.8093e-04 - val_loss: 1.7130 - val_mse: 1.7130\n",
      "Epoch 544/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 3.5964e-04 - mse: 3.5964e-04 - val_loss: 1.7479 - val_mse: 1.7479\n",
      "Epoch 545/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.3158e-04 - mse: 3.3158e-04 - val_loss: 1.7031 - val_mse: 1.7031\n",
      "Epoch 546/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.0606e-04 - mse: 3.0606e-04 - val_loss: 1.7213 - val_mse: 1.7213\n",
      "Epoch 547/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.5541e-04 - mse: 9.5541e-04 - val_loss: 1.6959 - val_mse: 1.6959\n",
      "Epoch 548/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.7711 - val_mse: 1.7711\n",
      "Epoch 549/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.6539 - val_mse: 1.6539\n",
      "Epoch 550/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.7541 - val_mse: 1.7541\n",
      "Epoch 551/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.9848e-04 - mse: 9.9848e-04 - val_loss: 1.6880 - val_mse: 1.6880\n",
      "Epoch 552/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.4020e-04 - mse: 9.4020e-04 - val_loss: 1.7123 - val_mse: 1.7123\n",
      "Epoch 553/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.7111 - val_mse: 1.7111\n",
      "Epoch 554/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.7837 - val_mse: 1.7837\n",
      "Epoch 555/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 1.7155 - val_mse: 1.7155\n",
      "Epoch 556/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 1.7092 - val_mse: 1.7092\n",
      "Epoch 557/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 1.6510 - val_mse: 1.6510\n",
      "Epoch 558/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 1.9695 - val_mse: 1.9695\n",
      "Epoch 559/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 1.6581 - val_mse: 1.6581\n",
      "Epoch 560/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 1.8219 - val_mse: 1.8219\n",
      "Epoch 561/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 1.7032 - val_mse: 1.7032\n",
      "Epoch 562/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 1.7354 - val_mse: 1.7354\n",
      "Epoch 563/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 1.7387 - val_mse: 1.7387\n",
      "Epoch 564/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.7859 - val_mse: 1.7859\n",
      "Epoch 565/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.7339 - val_mse: 1.7339\n",
      "Epoch 566/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.7294 - val_mse: 1.7294\n",
      "Epoch 567/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.7982 - val_mse: 1.7982\n",
      "Epoch 568/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.6934 - val_mse: 1.6934\n",
      "Epoch 569/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.8592 - val_mse: 1.8592\n",
      "Epoch 570/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.6687 - val_mse: 1.6687\n",
      "Epoch 571/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.7765 - val_mse: 1.7765\n",
      "Epoch 572/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.6181 - val_mse: 1.6181\n",
      "Epoch 573/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 1.8609 - val_mse: 1.8609\n",
      "Epoch 574/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 1.6439 - val_mse: 1.6439\n",
      "Epoch 575/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 1.7287 - val_mse: 1.7287\n",
      "Epoch 576/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 1.5788 - val_mse: 1.5788\n",
      "Epoch 577/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 1.7531 - val_mse: 1.7531\n",
      "Epoch 578/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 1.6953 - val_mse: 1.6953\n",
      "Epoch 579/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 1.7822 - val_mse: 1.7822\n",
      "Epoch 580/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 1.6929 - val_mse: 1.6929\n",
      "Epoch 581/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.7844 - val_mse: 1.7844\n",
      "Epoch 582/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.6958 - val_mse: 1.6958\n",
      "Epoch 583/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.6855 - val_mse: 1.6855\n",
      "Epoch 584/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.7029 - val_mse: 1.7029\n",
      "Epoch 585/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 1.6920 - val_mse: 1.6920\n",
      "Epoch 586/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 1.8198 - val_mse: 1.8198\n",
      "Epoch 587/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 1.7920 - val_mse: 1.7920\n",
      "Epoch 588/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 1.5272 - val_mse: 1.5272\n",
      "Epoch 589/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 1.9021 - val_mse: 1.9021\n",
      "Epoch 590/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 1.5723 - val_mse: 1.5723\n",
      "Epoch 591/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 1.8596 - val_mse: 1.8596\n",
      "Epoch 592/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 1.4468 - val_mse: 1.4468\n",
      "Epoch 593/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 1.5430 - val_mse: 1.5430\n",
      "Epoch 594/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 1.7053 - val_mse: 1.7053\n",
      "Epoch 595/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 1.6125 - val_mse: 1.6125\n",
      "Epoch 596/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 1.7490 - val_mse: 1.7490\n",
      "Epoch 597/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 1.6834 - val_mse: 1.6834\n",
      "Epoch 598/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 1.7059 - val_mse: 1.7059\n",
      "Epoch 599/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.6940 - val_mse: 1.6940\n",
      "Epoch 600/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.6693 - val_mse: 1.6693\n",
      "Epoch 601/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.6847 - val_mse: 1.6847\n",
      "Epoch 602/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.6952 - val_mse: 1.6952\n",
      "Epoch 603/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.6878 - val_mse: 1.6878\n",
      "Epoch 604/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.5034e-04 - mse: 9.5034e-04 - val_loss: 1.6752 - val_mse: 1.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.8826e-04 - mse: 5.8826e-04 - val_loss: 1.6702 - val_mse: 1.6702\n",
      "Epoch 606/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.2268e-04 - mse: 4.2268e-04 - val_loss: 1.6981 - val_mse: 1.6981\n",
      "Epoch 607/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.1536e-04 - mse: 4.1536e-04 - val_loss: 1.6712 - val_mse: 1.6712\n",
      "Epoch 608/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.4432e-04 - mse: 3.4432e-04 - val_loss: 1.6739 - val_mse: 1.6739\n",
      "Epoch 609/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.9235e-04 - mse: 2.9235e-04 - val_loss: 1.6831 - val_mse: 1.6831\n",
      "Epoch 610/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.6884e-04 - mse: 2.6884e-04 - val_loss: 1.6747 - val_mse: 1.6747\n",
      "Epoch 611/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.9338e-04 - mse: 2.9338e-04 - val_loss: 1.6906 - val_mse: 1.6906\n",
      "Epoch 612/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.5685e-04 - mse: 5.5685e-04 - val_loss: 1.6808 - val_mse: 1.6808\n",
      "Epoch 613/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.5931e-04 - mse: 4.5931e-04 - val_loss: 1.6904 - val_mse: 1.6904\n",
      "Epoch 614/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.0160e-04 - mse: 3.0160e-04 - val_loss: 1.6717 - val_mse: 1.6717\n",
      "Epoch 615/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.6192e-04 - mse: 2.6192e-04 - val_loss: 1.6703 - val_mse: 1.6703\n",
      "Epoch 616/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.8543e-04 - mse: 1.8543e-04 - val_loss: 1.6905 - val_mse: 1.6905\n",
      "Epoch 617/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.6899e-04 - mse: 1.6899e-04 - val_loss: 1.6836 - val_mse: 1.6836\n",
      "Epoch 618/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.1705e-04 - mse: 1.1705e-04 - val_loss: 1.6812 - val_mse: 1.6812\n",
      "Epoch 619/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.3753e-04 - mse: 1.3753e-04 - val_loss: 1.6751 - val_mse: 1.6751\n",
      "Epoch 620/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.2081e-04 - mse: 1.2081e-04 - val_loss: 1.6806 - val_mse: 1.6806\n",
      "Epoch 621/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.0572e-05 - mse: 7.0572e-05 - val_loss: 1.6768 - val_mse: 1.6768\n",
      "Epoch 622/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.1141e-05 - mse: 6.1141e-05 - val_loss: 1.6845 - val_mse: 1.6845\n",
      "Epoch 623/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.5051e-05 - mse: 7.5051e-05 - val_loss: 1.6695 - val_mse: 1.6695\n",
      "Epoch 624/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.7237e-05 - mse: 5.7237e-05 - val_loss: 1.6711 - val_mse: 1.6711\n",
      "Epoch 625/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.5350e-05 - mse: 6.5350e-05 - val_loss: 1.6799 - val_mse: 1.6799\n",
      "Epoch 626/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.7467e-05 - mse: 6.7467e-05 - val_loss: 1.6772 - val_mse: 1.6772\n",
      "Epoch 627/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.9299e-05 - mse: 9.9299e-05 - val_loss: 1.6703 - val_mse: 1.6703\n",
      "Epoch 628/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.3588e-04 - mse: 1.3588e-04 - val_loss: 1.6784 - val_mse: 1.6784\n",
      "Epoch 629/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.4868e-04 - mse: 1.4868e-04 - val_loss: 1.6807 - val_mse: 1.6807\n",
      "Epoch 630/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.8199e-04 - mse: 1.8199e-04 - val_loss: 1.6657 - val_mse: 1.6657\n",
      "Epoch 631/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.3443e-04 - mse: 5.3443e-04 - val_loss: 1.6975 - val_mse: 1.6975\n",
      "Epoch 632/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.1103e-04 - mse: 5.1103e-04 - val_loss: 1.6759 - val_mse: 1.6759\n",
      "Epoch 633/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.2597e-04 - mse: 4.2597e-04 - val_loss: 1.6514 - val_mse: 1.6514\n",
      "Epoch 634/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.6889e-04 - mse: 8.6889e-04 - val_loss: 1.6504 - val_mse: 1.6504\n",
      "Epoch 635/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.8794e-04 - mse: 8.8794e-04 - val_loss: 1.6932 - val_mse: 1.6932\n",
      "Epoch 636/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.3958e-04 - mse: 7.3958e-04 - val_loss: 1.7000 - val_mse: 1.7000\n",
      "Epoch 637/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.6424 - val_mse: 1.6424\n",
      "Epoch 638/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.7230 - val_mse: 1.7230\n",
      "Epoch 639/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.6499 - val_mse: 1.6499\n",
      "Epoch 640/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.6993 - val_mse: 1.6993\n",
      "Epoch 641/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.6759 - val_mse: 1.6759\n",
      "Epoch 642/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 1.7499 - val_mse: 1.7499\n",
      "Epoch 643/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 1.7150 - val_mse: 1.7150\n",
      "Epoch 644/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 1.3790 - val_mse: 1.3790\n",
      "Epoch 645/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 1.7081 - val_mse: 1.7081\n",
      "Epoch 646/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0847 - mse: 0.0847 - val_loss: 1.3732 - val_mse: 1.3732\n",
      "Epoch 647/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 1.6524 - val_mse: 1.6524\n",
      "Epoch 648/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0760 - mse: 0.0760 - val_loss: 1.4619 - val_mse: 1.4619\n",
      "Epoch 649/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 1.5901 - val_mse: 1.5901\n",
      "Epoch 650/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 1.5397 - val_mse: 1.5397\n",
      "Epoch 651/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 1.5905 - val_mse: 1.5905\n",
      "Epoch 652/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 1.5949 - val_mse: 1.5949\n",
      "Epoch 653/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 1.5614 - val_mse: 1.5614\n",
      "Epoch 654/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 1.6114 - val_mse: 1.6114\n",
      "Epoch 655/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 1.5708 - val_mse: 1.5708\n",
      "Epoch 656/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 1.5680 - val_mse: 1.5680\n",
      "Epoch 657/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.5689 - val_mse: 1.5689\n",
      "Epoch 658/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.5741 - val_mse: 1.5741\n",
      "Epoch 659/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.5803 - val_mse: 1.5803\n",
      "Epoch 660/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.2601e-04 - mse: 9.2601e-04 - val_loss: 1.5892 - val_mse: 1.5892\n",
      "Epoch 661/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.8924e-04 - mse: 8.8924e-04 - val_loss: 1.5874 - val_mse: 1.5874\n",
      "Epoch 662/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.2401e-04 - mse: 7.2401e-04 - val_loss: 1.5777 - val_mse: 1.5777\n",
      "Epoch 663/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.5880 - val_mse: 1.5880\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.5865 - val_mse: 1.5865\n",
      "Epoch 665/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.5557 - val_mse: 1.5557\n",
      "Epoch 666/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.5984 - val_mse: 1.5984\n",
      "Epoch 667/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.5730 - val_mse: 1.5730\n",
      "Epoch 668/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.1817e-04 - mse: 9.1817e-04 - val_loss: 1.6044 - val_mse: 1.6044\n",
      "Epoch 669/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.9962e-04 - mse: 6.9962e-04 - val_loss: 1.5844 - val_mse: 1.5844\n",
      "Epoch 670/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.8698e-04 - mse: 6.8698e-04 - val_loss: 1.5880 - val_mse: 1.5880\n",
      "Epoch 671/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.7042e-04 - mse: 4.7042e-04 - val_loss: 1.5949 - val_mse: 1.5949\n",
      "Epoch 672/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.0170e-04 - mse: 3.0170e-04 - val_loss: 1.5807 - val_mse: 1.5807\n",
      "Epoch 673/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.6442e-04 - mse: 2.6442e-04 - val_loss: 1.5847 - val_mse: 1.5847\n",
      "Epoch 674/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.4372e-04 - mse: 2.4372e-04 - val_loss: 1.5861 - val_mse: 1.5861\n",
      "Epoch 675/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.9260e-04 - mse: 2.9260e-04 - val_loss: 1.5833 - val_mse: 1.5833\n",
      "Epoch 676/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.6923e-04 - mse: 3.6923e-04 - val_loss: 1.5959 - val_mse: 1.5959\n",
      "Epoch 677/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.1077e-04 - mse: 3.1077e-04 - val_loss: 1.5855 - val_mse: 1.5855\n",
      "Epoch 678/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.0149e-04 - mse: 4.0149e-04 - val_loss: 1.5773 - val_mse: 1.5773\n",
      "Epoch 679/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.8128e-04 - mse: 4.8128e-04 - val_loss: 1.5974 - val_mse: 1.5974\n",
      "Epoch 680/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.3272e-04 - mse: 5.3272e-04 - val_loss: 1.6022 - val_mse: 1.6022\n",
      "Epoch 681/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.3722e-04 - mse: 3.3722e-04 - val_loss: 1.5750 - val_mse: 1.5750\n",
      "Epoch 682/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.3971e-04 - mse: 2.3971e-04 - val_loss: 1.5968 - val_mse: 1.5968\n",
      "Epoch 683/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.9166e-04 - mse: 7.9166e-04 - val_loss: 1.5411 - val_mse: 1.5411\n",
      "Epoch 684/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.8676e-04 - mse: 8.8676e-04 - val_loss: 1.5940 - val_mse: 1.5940\n",
      "Epoch 685/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.9734e-04 - mse: 8.9734e-04 - val_loss: 1.5873 - val_mse: 1.5873\n",
      "Epoch 686/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.2643e-04 - mse: 9.2643e-04 - val_loss: 1.5500 - val_mse: 1.5500\n",
      "Epoch 687/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.3419e-04 - mse: 8.3419e-04 - val_loss: 1.5867 - val_mse: 1.5867\n",
      "Epoch 688/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.1906e-04 - mse: 5.1906e-04 - val_loss: 1.5673 - val_mse: 1.5673\n",
      "Epoch 689/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.7690e-04 - mse: 3.7690e-04 - val_loss: 1.5973 - val_mse: 1.5973\n",
      "Epoch 690/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.2028e-04 - mse: 2.2028e-04 - val_loss: 1.5694 - val_mse: 1.5694\n",
      "Epoch 691/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.6205e-04 - mse: 2.6205e-04 - val_loss: 1.5819 - val_mse: 1.5819\n",
      "Epoch 692/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.2166e-04 - mse: 2.2166e-04 - val_loss: 1.5824 - val_mse: 1.5824\n",
      "Epoch 693/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.3081e-04 - mse: 2.3081e-04 - val_loss: 1.5932 - val_mse: 1.5932\n",
      "Epoch 694/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.5535e-04 - mse: 1.5535e-04 - val_loss: 1.5864 - val_mse: 1.5864\n",
      "Epoch 695/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.1333e-04 - mse: 1.1333e-04 - val_loss: 1.5683 - val_mse: 1.5683\n",
      "Epoch 696/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.0388e-04 - mse: 1.0388e-04 - val_loss: 1.5868 - val_mse: 1.5868\n",
      "Epoch 697/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.3891e-04 - mse: 1.3891e-04 - val_loss: 1.5812 - val_mse: 1.5812\n",
      "Epoch 698/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.5111e-05 - mse: 8.5111e-05 - val_loss: 1.5761 - val_mse: 1.5761\n",
      "Epoch 699/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.5037e-04 - mse: 1.5037e-04 - val_loss: 1.5837 - val_mse: 1.5837\n",
      "Epoch 700/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.1565e-04 - mse: 1.1565e-04 - val_loss: 1.5841 - val_mse: 1.5841\n",
      "Epoch 701/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.7007e-05 - mse: 8.7007e-05 - val_loss: 1.5769 - val_mse: 1.5769\n",
      "Epoch 702/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.8508e-05 - mse: 7.8508e-05 - val_loss: 1.5948 - val_mse: 1.5948\n",
      "Epoch 703/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.6083e-04 - mse: 1.6083e-04 - val_loss: 1.5662 - val_mse: 1.5662\n",
      "Epoch 704/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.6263e-04 - mse: 3.6263e-04 - val_loss: 1.5791 - val_mse: 1.5791\n",
      "Epoch 705/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.6909e-04 - mse: 4.6909e-04 - val_loss: 1.6011 - val_mse: 1.6011\n",
      "Epoch 706/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.0171e-04 - mse: 3.0171e-04 - val_loss: 1.5914 - val_mse: 1.5914\n",
      "Epoch 707/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.0310e-04 - mse: 5.0310e-04 - val_loss: 1.5664 - val_mse: 1.5664\n",
      "Epoch 708/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.7399e-04 - mse: 6.7399e-04 - val_loss: 1.6055 - val_mse: 1.6055\n",
      "Epoch 709/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.5971e-04 - mse: 7.5971e-04 - val_loss: 1.5936 - val_mse: 1.5936\n",
      "Epoch 710/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.5589 - val_mse: 1.5589\n",
      "Epoch 711/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.5722 - val_mse: 1.5722\n",
      "Epoch 712/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.5660 - val_mse: 1.5660\n",
      "Epoch 713/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.9772e-04 - mse: 8.9772e-04 - val_loss: 1.5679 - val_mse: 1.5679\n",
      "Epoch 714/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.4314e-04 - mse: 9.4314e-04 - val_loss: 1.5846 - val_mse: 1.5846\n",
      "Epoch 715/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.6028 - val_mse: 1.6028\n",
      "Epoch 716/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.6007 - val_mse: 1.6007\n",
      "Epoch 717/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.5762 - val_mse: 1.5762\n",
      "Epoch 718/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.6012 - val_mse: 1.6012\n",
      "Epoch 719/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 1.5500 - val_mse: 1.5500\n",
      "Epoch 720/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.5576 - val_mse: 1.5576\n",
      "Epoch 721/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.6771 - val_mse: 1.6771\n",
      "Epoch 722/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.5597 - val_mse: 1.5597\n",
      "Epoch 723/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 1.5427 - val_mse: 1.5427\n",
      "Epoch 724/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 1.5107 - val_mse: 1.5107\n",
      "Epoch 725/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 1.5814 - val_mse: 1.5814\n",
      "Epoch 726/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 1.5802 - val_mse: 1.5802\n",
      "Epoch 727/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 1.4257 - val_mse: 1.4257\n",
      "Epoch 728/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 1.5338 - val_mse: 1.5338\n",
      "Epoch 729/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 1.6171 - val_mse: 1.6171\n",
      "Epoch 730/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 1.6234 - val_mse: 1.6234\n",
      "Epoch 731/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 1.5478 - val_mse: 1.5478\n",
      "Epoch 732/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 1.6785 - val_mse: 1.6785\n",
      "Epoch 733/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 1.5674 - val_mse: 1.5674\n",
      "Epoch 734/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 1.5185 - val_mse: 1.5185\n",
      "Epoch 735/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 1.5051 - val_mse: 1.5051\n",
      "Epoch 736/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 1.4450 - val_mse: 1.4450\n",
      "Epoch 737/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 1.4793 - val_mse: 1.4793\n",
      "Epoch 738/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 1.5338 - val_mse: 1.5338\n",
      "Epoch 739/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 1.4869 - val_mse: 1.4869\n",
      "Epoch 740/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 1.4920 - val_mse: 1.4920\n",
      "Epoch 741/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 1.4335 - val_mse: 1.4335\n",
      "Epoch 742/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 1.4273 - val_mse: 1.4273\n",
      "Epoch 743/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 1.5187 - val_mse: 1.5187\n",
      "Epoch 744/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 1.4266 - val_mse: 1.4266\n",
      "Epoch 745/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 1.4997 - val_mse: 1.4997\n",
      "Epoch 746/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 1.4561 - val_mse: 1.4561\n",
      "Epoch 747/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 1.4451 - val_mse: 1.4451\n",
      "Epoch 748/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 1.5134 - val_mse: 1.5134\n",
      "Epoch 749/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.5022 - val_mse: 1.5022\n",
      "Epoch 750/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 1.4624 - val_mse: 1.4624\n",
      "Epoch 751/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 1.5030 - val_mse: 1.5030\n",
      "Epoch 752/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.4747 - val_mse: 1.4747\n",
      "Epoch 753/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.5306 - val_mse: 1.5306\n",
      "Epoch 754/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.5495 - val_mse: 1.5495\n",
      "Epoch 755/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.4358 - val_mse: 1.4358\n",
      "Epoch 756/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.5058 - val_mse: 1.5058\n",
      "Epoch 757/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.4847 - val_mse: 1.4847\n",
      "Epoch 758/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.5059 - val_mse: 1.5059\n",
      "Epoch 759/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.3023e-04 - mse: 6.3023e-04 - val_loss: 1.4773 - val_mse: 1.4773\n",
      "Epoch 760/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.3969e-04 - mse: 5.3969e-04 - val_loss: 1.4827 - val_mse: 1.4827\n",
      "Epoch 761/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.8002e-04 - mse: 3.8002e-04 - val_loss: 1.4963 - val_mse: 1.4963\n",
      "Epoch 762/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.2471e-04 - mse: 2.2471e-04 - val_loss: 1.4925 - val_mse: 1.4925\n",
      "Epoch 763/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.0071e-04 - mse: 2.0071e-04 - val_loss: 1.5048 - val_mse: 1.5048\n",
      "Epoch 764/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.5057 - val_mse: 1.5057\n",
      "Epoch 765/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.6310e-04 - mse: 6.6310e-04 - val_loss: 1.5206 - val_mse: 1.5206\n",
      "Epoch 766/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.4920 - val_mse: 1.4920\n",
      "Epoch 767/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.4598 - val_mse: 1.4598\n",
      "Epoch 768/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.4059e-04 - mse: 8.4059e-04 - val_loss: 1.5058 - val_mse: 1.5058\n",
      "Epoch 769/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.4374e-04 - mse: 7.4374e-04 - val_loss: 1.5215 - val_mse: 1.5215\n",
      "Epoch 770/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.4951 - val_mse: 1.4951\n",
      "Epoch 771/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.5063 - val_mse: 1.5063\n",
      "Epoch 772/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.4971 - val_mse: 1.4971\n",
      "Epoch 773/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.4987 - val_mse: 1.4987\n",
      "Epoch 774/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.4471 - val_mse: 1.4471\n",
      "Epoch 775/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.5414 - val_mse: 1.5414\n",
      "Epoch 776/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.4923 - val_mse: 1.4923\n",
      "Epoch 777/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.4782 - val_mse: 1.4782\n",
      "Epoch 778/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.5221 - val_mse: 1.5221\n",
      "Epoch 779/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.4594 - val_mse: 1.4594\n",
      "Epoch 780/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.4826 - val_mse: 1.4826\n",
      "Epoch 781/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.4735 - val_mse: 1.4735\n",
      "Epoch 782/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.5179 - val_mse: 1.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.4942 - val_mse: 1.4942\n",
      "Epoch 784/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.4772 - val_mse: 1.4772\n",
      "Epoch 785/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.4971 - val_mse: 1.4971\n",
      "Epoch 786/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.4878 - val_mse: 1.4878\n",
      "Epoch 787/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.8602e-04 - mse: 8.8602e-04 - val_loss: 1.5064 - val_mse: 1.5064\n",
      "Epoch 788/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.6487e-04 - mse: 6.6487e-04 - val_loss: 1.5039 - val_mse: 1.5039\n",
      "Epoch 789/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.5889e-04 - mse: 5.5889e-04 - val_loss: 1.4987 - val_mse: 1.4987\n",
      "Epoch 790/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.8670e-04 - mse: 5.8670e-04 - val_loss: 1.4999 - val_mse: 1.4999\n",
      "Epoch 791/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.5439e-04 - mse: 5.5439e-04 - val_loss: 1.4708 - val_mse: 1.4708\n",
      "Epoch 792/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.5760 - val_mse: 1.5760\n",
      "Epoch 793/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 1.4381 - val_mse: 1.4381\n",
      "Epoch 794/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 1.5357 - val_mse: 1.5357\n",
      "Epoch 795/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 1.4745 - val_mse: 1.4745\n",
      "Epoch 796/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.4963 - val_mse: 1.4963\n",
      "Epoch 797/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.5305 - val_mse: 1.5305\n",
      "Epoch 798/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 1.4754 - val_mse: 1.4754\n",
      "Epoch 799/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.4999 - val_mse: 1.4999\n",
      "Epoch 800/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.4940 - val_mse: 1.4940\n",
      "Epoch 801/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.4546 - val_mse: 1.4546\n",
      "Epoch 802/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.4977 - val_mse: 1.4977\n",
      "Epoch 803/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.4799 - val_mse: 1.4799\n",
      "Epoch 804/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 1.5918 - val_mse: 1.5918\n",
      "Epoch 805/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 1.4188 - val_mse: 1.4188\n",
      "Epoch 806/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 1.4764 - val_mse: 1.4764\n",
      "Epoch 807/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 1.4486 - val_mse: 1.4486\n",
      "Epoch 808/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 1.5835 - val_mse: 1.5835\n",
      "Epoch 809/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 1.4671 - val_mse: 1.4671\n",
      "Epoch 810/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 1.4846 - val_mse: 1.4846\n",
      "Epoch 811/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 1.4586 - val_mse: 1.4586\n",
      "Epoch 812/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 1.4777 - val_mse: 1.4777\n",
      "Epoch 813/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.5098 - val_mse: 1.5098\n",
      "Epoch 814/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 1.4369 - val_mse: 1.4369\n",
      "Epoch 815/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 1.5623 - val_mse: 1.5623\n",
      "Epoch 816/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 1.4910 - val_mse: 1.4910\n",
      "Epoch 817/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 1.5194 - val_mse: 1.5194\n",
      "Epoch 818/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 1.5260 - val_mse: 1.5260\n",
      "Epoch 819/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 1.5230 - val_mse: 1.5230\n",
      "Epoch 820/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 1.4509 - val_mse: 1.4509\n",
      "Epoch 821/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 1.5488 - val_mse: 1.5488\n",
      "Epoch 822/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 1.5042 - val_mse: 1.5042\n",
      "Epoch 823/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.4723 - val_mse: 1.4723\n",
      "Epoch 824/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.4737 - val_mse: 1.4737\n",
      "Epoch 825/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.5189 - val_mse: 1.5189\n",
      "Epoch 826/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.9061e-04 - mse: 7.9061e-04 - val_loss: 1.4839 - val_mse: 1.4839\n",
      "Epoch 827/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.7738e-04 - mse: 5.7738e-04 - val_loss: 1.5095 - val_mse: 1.5095\n",
      "Epoch 828/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.5630e-04 - mse: 3.5630e-04 - val_loss: 1.4952 - val_mse: 1.4952\n",
      "Epoch 829/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.9045e-04 - mse: 6.9045e-04 - val_loss: 1.5262 - val_mse: 1.5262\n",
      "Epoch 830/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.7446e-04 - mse: 4.7446e-04 - val_loss: 1.4985 - val_mse: 1.4985\n",
      "Epoch 831/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.1391e-04 - mse: 4.1391e-04 - val_loss: 1.5058 - val_mse: 1.5058\n",
      "Epoch 832/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.8932e-04 - mse: 2.8932e-04 - val_loss: 1.5108 - val_mse: 1.5108\n",
      "Epoch 833/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.4683 - val_mse: 1.4683\n",
      "Epoch 834/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.4888 - val_mse: 1.4888\n",
      "Epoch 835/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.5153 - val_mse: 1.5153\n",
      "Epoch 836/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.4906 - val_mse: 1.4906\n",
      "Epoch 837/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.5403 - val_mse: 1.5403\n",
      "Epoch 838/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.4246e-04 - mse: 8.4246e-04 - val_loss: 1.4905 - val_mse: 1.4905\n",
      "Epoch 839/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.4711e-04 - mse: 7.4711e-04 - val_loss: 1.5465 - val_mse: 1.5465\n",
      "Epoch 840/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.1711e-04 - mse: 7.1711e-04 - val_loss: 1.4976 - val_mse: 1.4976\n",
      "Epoch 841/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.0953e-04 - mse: 6.0953e-04 - val_loss: 1.5119 - val_mse: 1.5119\n",
      "Epoch 842/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.8059e-04 - mse: 4.8059e-04 - val_loss: 1.5133 - val_mse: 1.5133\n",
      "Epoch 843/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.1069e-04 - mse: 4.1069e-04 - val_loss: 1.4967 - val_mse: 1.4967\n",
      "Epoch 844/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.2400e-04 - mse: 4.2400e-04 - val_loss: 1.5425 - val_mse: 1.5425\n",
      "Epoch 845/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.4415e-04 - mse: 4.4415e-04 - val_loss: 1.5031 - val_mse: 1.5031\n",
      "Epoch 846/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.8468e-04 - mse: 3.8468e-04 - val_loss: 1.5233 - val_mse: 1.5233\n",
      "Epoch 847/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.8673e-04 - mse: 6.8673e-04 - val_loss: 1.4762 - val_mse: 1.4762\n",
      "Epoch 848/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.7009e-04 - mse: 6.7009e-04 - val_loss: 1.5312 - val_mse: 1.5312\n",
      "Epoch 849/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.8930e-04 - mse: 5.8930e-04 - val_loss: 1.4895 - val_mse: 1.4895\n",
      "Epoch 850/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.1682e-04 - mse: 5.1682e-04 - val_loss: 1.5085 - val_mse: 1.5085\n",
      "Epoch 851/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.4140e-04 - mse: 9.4140e-04 - val_loss: 1.5177 - val_mse: 1.5177\n",
      "Epoch 852/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.4972 - val_mse: 1.4972\n",
      "Epoch 853/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.6744e-04 - mse: 7.6744e-04 - val_loss: 1.5233 - val_mse: 1.5233\n",
      "Epoch 854/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.5047e-04 - mse: 5.5047e-04 - val_loss: 1.4894 - val_mse: 1.4894\n",
      "Epoch 855/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.9373e-04 - mse: 6.9373e-04 - val_loss: 1.5290 - val_mse: 1.5290\n",
      "Epoch 856/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.5714e-04 - mse: 7.5714e-04 - val_loss: 1.4972 - val_mse: 1.4972\n",
      "Epoch 857/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.4143e-04 - mse: 6.4143e-04 - val_loss: 1.5413 - val_mse: 1.5413\n",
      "Epoch 858/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.4640 - val_mse: 1.4640\n",
      "Epoch 859/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.5100 - val_mse: 1.5100\n",
      "Epoch 860/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.5556 - val_mse: 1.5556\n",
      "Epoch 861/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.4866 - val_mse: 1.4866\n",
      "Epoch 862/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.5625 - val_mse: 1.5625\n",
      "Epoch 863/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 1.3902 - val_mse: 1.3902\n",
      "Epoch 864/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 1.6087 - val_mse: 1.6087\n",
      "Epoch 865/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 1.3724 - val_mse: 1.3724\n",
      "Epoch 866/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 1.5359 - val_mse: 1.5359\n",
      "Epoch 867/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 1.4688 - val_mse: 1.4688\n",
      "Epoch 868/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 1.8065 - val_mse: 1.8065\n",
      "Epoch 869/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 1.3168 - val_mse: 1.3168\n",
      "Epoch 870/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0719 - mse: 0.0719 - val_loss: 1.3965 - val_mse: 1.3965\n",
      "Epoch 871/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 1.5027 - val_mse: 1.5027\n",
      "Epoch 872/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 1.4126 - val_mse: 1.4126\n",
      "Epoch 873/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 1.3770 - val_mse: 1.3770\n",
      "Epoch 874/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 1.3914 - val_mse: 1.3914\n",
      "Epoch 875/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 1.4877 - val_mse: 1.4877\n",
      "Epoch 876/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 1.4951 - val_mse: 1.4951\n",
      "Epoch 877/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 1.5558 - val_mse: 1.5558\n",
      "Epoch 878/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 1.4748 - val_mse: 1.4748\n",
      "Epoch 879/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.4852 - val_mse: 1.4852\n",
      "Epoch 880/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.4624 - val_mse: 1.4624\n",
      "Epoch 881/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.4843 - val_mse: 1.4843\n",
      "Epoch 882/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.4818 - val_mse: 1.4818\n",
      "Epoch 883/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.6440e-04 - mse: 6.6440e-04 - val_loss: 1.4976 - val_mse: 1.4976\n",
      "Epoch 884/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.7816e-04 - mse: 4.7816e-04 - val_loss: 1.4837 - val_mse: 1.4837\n",
      "Epoch 885/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.5023e-04 - mse: 4.5023e-04 - val_loss: 1.4840 - val_mse: 1.4840\n",
      "Epoch 886/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.6431e-04 - mse: 2.6431e-04 - val_loss: 1.4907 - val_mse: 1.4907\n",
      "Epoch 887/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.0741e-04 - mse: 2.0741e-04 - val_loss: 1.4985 - val_mse: 1.4985\n",
      "Epoch 888/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.7694e-04 - mse: 2.7694e-04 - val_loss: 1.4876 - val_mse: 1.4876\n",
      "Epoch 889/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.8930e-04 - mse: 1.8930e-04 - val_loss: 1.4831 - val_mse: 1.4831\n",
      "Epoch 890/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.7295e-04 - mse: 1.7295e-04 - val_loss: 1.4897 - val_mse: 1.4897\n",
      "Epoch 891/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.1209e-04 - mse: 1.1209e-04 - val_loss: 1.4895 - val_mse: 1.4895\n",
      "Epoch 892/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.4954e-05 - mse: 7.4954e-05 - val_loss: 1.4941 - val_mse: 1.4941\n",
      "Epoch 893/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.2488e-05 - mse: 6.2488e-05 - val_loss: 1.4905 - val_mse: 1.4905\n",
      "Epoch 894/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.7609e-05 - mse: 4.7609e-05 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "Epoch 895/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.1189e-05 - mse: 5.1189e-05 - val_loss: 1.4891 - val_mse: 1.4891\n",
      "Epoch 896/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.1921e-05 - mse: 5.1921e-05 - val_loss: 1.5004 - val_mse: 1.5004\n",
      "Epoch 897/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.3673e-05 - mse: 4.3673e-05 - val_loss: 1.4925 - val_mse: 1.4925\n",
      "Epoch 898/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.4296e-05 - mse: 3.4296e-05 - val_loss: 1.4952 - val_mse: 1.4952\n",
      "Epoch 899/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.0138e-05 - mse: 3.0138e-05 - val_loss: 1.4946 - val_mse: 1.4946\n",
      "Epoch 900/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.7152e-05 - mse: 2.7152e-05 - val_loss: 1.4939 - val_mse: 1.4939\n",
      "Epoch 901/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.6581e-05 - mse: 3.6581e-05 - val_loss: 1.4889 - val_mse: 1.4889\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 9.2403e-05 - mse: 9.2403e-05 - val_loss: 1.4983 - val_mse: 1.4983\n",
      "Epoch 903/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.4541e-05 - mse: 9.4541e-05 - val_loss: 1.4970 - val_mse: 1.4970\n",
      "Epoch 904/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 6.7861e-05 - mse: 6.7861e-05 - val_loss: 1.4910 - val_mse: 1.4910\n",
      "Epoch 905/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.9385e-05 - mse: 5.9385e-05 - val_loss: 1.4975 - val_mse: 1.4975\n",
      "Epoch 906/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 3.6732e-05 - mse: 3.6732e-05 - val_loss: 1.4951 - val_mse: 1.4951\n",
      "Epoch 907/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.8248e-05 - mse: 2.8248e-05 - val_loss: 1.4945 - val_mse: 1.4945\n",
      "Epoch 908/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.5404e-05 - mse: 2.5404e-05 - val_loss: 1.4956 - val_mse: 1.4956\n",
      "Epoch 909/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.9472e-05 - mse: 2.9472e-05 - val_loss: 1.4941 - val_mse: 1.4941\n",
      "Epoch 910/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.6605e-05 - mse: 2.6605e-05 - val_loss: 1.4953 - val_mse: 1.4953\n",
      "Epoch 911/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 3.6860e-05 - mse: 3.6860e-05 - val_loss: 1.4908 - val_mse: 1.4908\n",
      "Epoch 912/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 4.2193e-05 - mse: 4.2193e-05 - val_loss: 1.4988 - val_mse: 1.4988\n",
      "Epoch 913/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.6574e-04 - mse: 1.6574e-04 - val_loss: 1.4819 - val_mse: 1.4819\n",
      "Epoch 914/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.2823e-04 - mse: 1.2823e-04 - val_loss: 1.5105 - val_mse: 1.5105\n",
      "Epoch 915/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.8606e-04 - mse: 2.8606e-04 - val_loss: 1.4993 - val_mse: 1.4993\n",
      "Epoch 916/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.5021e-04 - mse: 2.5021e-04 - val_loss: 1.4995 - val_mse: 1.4995\n",
      "Epoch 917/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.1434e-04 - mse: 2.1434e-04 - val_loss: 1.4951 - val_mse: 1.4951\n",
      "Epoch 918/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 7.6087e-04 - mse: 7.6087e-04 - val_loss: 1.5307 - val_mse: 1.5307\n",
      "Epoch 919/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 1.4520 - val_mse: 1.4520\n",
      "Epoch 920/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 1.5121 - val_mse: 1.5121\n",
      "Epoch 921/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.5124 - val_mse: 1.5124\n",
      "Epoch 922/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.4977 - val_mse: 1.4977\n",
      "Epoch 923/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.5158 - val_mse: 1.5158\n",
      "Epoch 924/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.4738 - val_mse: 1.4738\n",
      "Epoch 925/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.4869 - val_mse: 1.4869\n",
      "Epoch 926/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.5020 - val_mse: 1.5020\n",
      "Epoch 927/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.5107 - val_mse: 1.5107\n",
      "Epoch 928/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.4810 - val_mse: 1.4810\n",
      "Epoch 929/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.4871 - val_mse: 1.4871\n",
      "Epoch 930/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.5152 - val_mse: 1.5152\n",
      "Epoch 931/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.4655 - val_mse: 1.4655\n",
      "Epoch 932/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 1.5241 - val_mse: 1.5241\n",
      "Epoch 933/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.4403 - val_mse: 1.4403\n",
      "Epoch 934/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.5301 - val_mse: 1.5301\n",
      "Epoch 935/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.4311 - val_mse: 1.4311\n",
      "Epoch 936/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.5160 - val_mse: 1.5160\n",
      "Epoch 937/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.4241 - val_mse: 1.4241\n",
      "Epoch 938/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.4774 - val_mse: 1.4774\n",
      "Epoch 939/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 1.4433 - val_mse: 1.4433\n",
      "Epoch 940/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 1.5414 - val_mse: 1.5414\n",
      "Epoch 941/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 1.4447 - val_mse: 1.4447\n",
      "Epoch 942/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 1.4393 - val_mse: 1.4393\n",
      "Epoch 943/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 1.4690 - val_mse: 1.4690\n",
      "Epoch 944/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 1.4491 - val_mse: 1.4491\n",
      "Epoch 945/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 1.4368 - val_mse: 1.4368\n",
      "Epoch 946/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.4203 - val_mse: 1.4203\n",
      "Epoch 947/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 1.4474 - val_mse: 1.4474\n",
      "Epoch 948/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.4371 - val_mse: 1.4371\n",
      "Epoch 949/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.4774 - val_mse: 1.4774\n",
      "Epoch 950/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.4383 - val_mse: 1.4383\n",
      "Epoch 951/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 9.0624e-04 - mse: 9.0624e-04 - val_loss: 1.4768 - val_mse: 1.4768\n",
      "Epoch 952/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.4845 - val_mse: 1.4845\n",
      "Epoch 953/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.4151 - val_mse: 1.4151\n",
      "Epoch 954/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.4843 - val_mse: 1.4843\n",
      "Epoch 955/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.4775 - val_mse: 1.4775\n",
      "Epoch 956/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.4779 - val_mse: 1.4779\n",
      "Epoch 957/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.4623 - val_mse: 1.4623\n",
      "Epoch 958/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.4386 - val_mse: 1.4386\n",
      "Epoch 959/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 1.4747 - val_mse: 1.4747\n",
      "Epoch 960/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.4553 - val_mse: 1.4553\n",
      "Epoch 961/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.4989 - val_mse: 1.4989\n",
      "Epoch 962/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.4083 - val_mse: 1.4083\n",
      "Epoch 963/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.4851 - val_mse: 1.4851\n",
      "Epoch 964/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.4285 - val_mse: 1.4285\n",
      "Epoch 965/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.4781 - val_mse: 1.4781\n",
      "Epoch 966/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.4644 - val_mse: 1.4644\n",
      "Epoch 967/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 1.4515 - val_mse: 1.4515\n",
      "Epoch 968/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 1.5017 - val_mse: 1.5017\n",
      "Epoch 969/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 1.4056 - val_mse: 1.4056\n",
      "Epoch 970/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 1.4338 - val_mse: 1.4338\n",
      "Epoch 971/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 1.4910 - val_mse: 1.4910\n",
      "Epoch 972/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 1.5148 - val_mse: 1.5148\n",
      "Epoch 973/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 1.4597 - val_mse: 1.4597\n",
      "Epoch 974/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.4892 - val_mse: 1.4892\n",
      "Epoch 975/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 1.4205 - val_mse: 1.4205\n",
      "Epoch 976/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 1.4403 - val_mse: 1.4403\n",
      "Epoch 977/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 1.4481 - val_mse: 1.4481\n",
      "Epoch 978/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 1.4380 - val_mse: 1.4380\n",
      "Epoch 979/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 1.4760 - val_mse: 1.4760\n",
      "Epoch 980/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 1.4580 - val_mse: 1.4580\n",
      "Epoch 981/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 1.4199 - val_mse: 1.4199\n",
      "Epoch 982/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 1.4809 - val_mse: 1.4809\n",
      "Epoch 983/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 1.4145 - val_mse: 1.4145\n",
      "Epoch 984/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 1.5057 - val_mse: 1.5057\n",
      "Epoch 985/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 1.4566 - val_mse: 1.4566\n",
      "Epoch 986/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.4830 - val_mse: 1.4830\n",
      "Epoch 987/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.5001 - val_mse: 1.5001\n",
      "Epoch 988/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.4520 - val_mse: 1.4520\n",
      "Epoch 989/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.4747 - val_mse: 1.4747\n",
      "Epoch 990/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.4737 - val_mse: 1.4737\n",
      "Epoch 991/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 1.4158 - val_mse: 1.4158\n",
      "Epoch 992/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 1.5153 - val_mse: 1.5153\n",
      "Epoch 993/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 1.4324 - val_mse: 1.4324\n",
      "Epoch 994/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 1.4560 - val_mse: 1.4560\n",
      "Epoch 995/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 1.5046 - val_mse: 1.5046\n",
      "Epoch 996/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 1.4494 - val_mse: 1.4494\n",
      "Epoch 997/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 1.4717 - val_mse: 1.4717\n",
      "Epoch 998/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 1.4128 - val_mse: 1.4128\n",
      "Epoch 999/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 1.4822 - val_mse: 1.4822\n",
      "Epoch 1000/1000\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 1.4387 - val_mse: 1.4387\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.5666 - mse: 1.5666\n",
      "Mean Squared Error on Test Data: 1.5666406154632568\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer (single neuron for regression)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a092ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 846us/step\n",
      "0.0388986013986014\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(spearmanr(y_pred, y_test).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6cad815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.61859024e-01],\n",
       "       [ 9.48884368e-01],\n",
       "       [-7.30958208e-02],\n",
       "       [ 9.39109981e-01],\n",
       "       [ 2.10482687e-01],\n",
       "       [ 6.32791221e-01],\n",
       "       [-1.92379475e-01],\n",
       "       [-4.63664010e-02],\n",
       "       [-1.17511988e+00],\n",
       "       [ 8.10114145e-01],\n",
       "       [ 9.28943977e-04],\n",
       "       [ 3.56522471e-01],\n",
       "       [ 3.96573812e-01],\n",
       "       [ 4.49059680e-02],\n",
       "       [ 5.72784126e-01],\n",
       "       [ 2.22005606e+00],\n",
       "       [ 3.49736243e-01],\n",
       "       [ 1.43725276e+00],\n",
       "       [-5.59917867e-01],\n",
       "       [ 4.31296259e-01],\n",
       "       [ 1.26706481e-01],\n",
       "       [-4.18957204e-01],\n",
       "       [ 4.30538893e-01],\n",
       "       [ 1.04075718e+00],\n",
       "       [ 8.38241041e-01],\n",
       "       [ 3.63927424e-01],\n",
       "       [-3.62140357e-01],\n",
       "       [-2.83931736e-02],\n",
       "       [-2.51420408e-01],\n",
       "       [-2.77214855e-01],\n",
       "       [-4.59460676e-01],\n",
       "       [-2.33200371e-01],\n",
       "       [ 2.31005326e-01],\n",
       "       [ 1.41154438e-01],\n",
       "       [-4.41422999e-01],\n",
       "       [ 9.88145232e-01],\n",
       "       [ 5.76259196e-01],\n",
       "       [-2.89449185e-01],\n",
       "       [ 2.21805632e-01],\n",
       "       [ 6.41937375e-01],\n",
       "       [ 1.54803932e-01],\n",
       "       [ 2.16349506e+00],\n",
       "       [ 8.78843427e-01],\n",
       "       [ 6.06176555e-01],\n",
       "       [-1.06838755e-01],\n",
       "       [-4.23841208e-01],\n",
       "       [-3.69472057e-01],\n",
       "       [ 4.45982546e-01],\n",
       "       [ 3.23168725e-01],\n",
       "       [-6.98422119e-02],\n",
       "       [ 7.16649950e-01],\n",
       "       [-5.90070188e-01],\n",
       "       [ 4.49908465e-01],\n",
       "       [ 6.22050166e-01],\n",
       "       [-2.05860976e-02],\n",
       "       [ 1.65822580e-02],\n",
       "       [ 6.99536443e-01],\n",
       "       [-2.71293461e-01],\n",
       "       [ 1.08470924e-01],\n",
       "       [-1.83187366e-01],\n",
       "       [ 2.15490627e+00],\n",
       "       [ 1.15749419e+00],\n",
       "       [ 7.42323026e-02],\n",
       "       [ 1.66827828e-01],\n",
       "       [ 1.67134774e+00]], dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "63388ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.44319694e-01,  1.32341000e+00,  2.01798494e-01,  5.12722564e-01,\n",
       "        5.46301421e-01, -2.04866312e-01,  3.30494920e+00,  1.71354028e-01,\n",
       "       -5.13327563e-03,  1.71254820e+00, -3.16178244e-01, -1.24481800e-01,\n",
       "        5.43005269e-01,  6.15113337e+00,  8.25401690e-02,  3.65625081e-01,\n",
       "        2.51031047e-01,  8.11774695e-02,  1.25656724e+00,  3.57000985e-01,\n",
       "       -8.23516026e-02,  1.37418714e+00, -1.19966610e-01,  3.29283970e-02,\n",
       "       -4.04038765e-01,  1.96311529e-01,  1.05095363e-01,  1.27149134e-02,\n",
       "        1.18126587e-01,  6.96176186e-01,  4.20970921e-01, -1.09654698e-01,\n",
       "        2.71843447e-01,  9.32710224e-01, -4.44789193e-01, -2.44404718e-02,\n",
       "        5.98348862e-01, -7.76042300e-01, -3.38773890e-01,  4.78901050e-02,\n",
       "       -2.07412530e-02,  3.31388464e-02, -1.25738963e-01, -9.54835852e-02,\n",
       "        1.71587946e-01, -1.28966178e+00, -3.22010423e-01, -4.77501202e-01,\n",
       "        5.46469696e-01, -2.49762829e-01,  4.93477944e-02, -4.78190931e-02,\n",
       "       -2.19393096e-01,  6.09053736e-01, -1.98986509e-01, -3.89972495e-01,\n",
       "        1.58190358e-01,  1.10206159e-01, -5.42592961e-01, -3.04470217e-01,\n",
       "       -1.53631940e+00,  3.24191066e-01, -2.47198358e-01,  5.66304198e-01,\n",
       "       -1.15172522e-01])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa778417",
   "metadata": {},
   "outputs": [],
   "source": [
    "20**12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c37c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
